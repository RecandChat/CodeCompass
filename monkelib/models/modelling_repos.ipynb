{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>stars</th>\n",
       "      <th>language</th>\n",
       "      <th>num_forks</th>\n",
       "      <th>open_issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54346799</td>\n",
       "      <td>publicapis</td>\n",
       "      <td>collective list free APIs</td>\n",
       "      <td>https://api.github.com/repos/public-apis/publi...</td>\n",
       "      <td>278839</td>\n",
       "      <td>Python</td>\n",
       "      <td>31309</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83222441</td>\n",
       "      <td>systemdesignprimer</td>\n",
       "      <td>Learn design largescale systems Prep system de...</td>\n",
       "      <td>https://api.github.com/repos/donnemartin/syste...</td>\n",
       "      <td>245714</td>\n",
       "      <td>Python</td>\n",
       "      <td>42633</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63476337</td>\n",
       "      <td>Python</td>\n",
       "      <td>Algorithms implemented Python</td>\n",
       "      <td>https://api.github.com/repos/TheAlgorithms/Python</td>\n",
       "      <td>175617</td>\n",
       "      <td>Python</td>\n",
       "      <td>43858</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123458551</td>\n",
       "      <td>Python100Days</td>\n",
       "      <td>Python 100</td>\n",
       "      <td>https://api.github.com/repos/jackfrued/Python-...</td>\n",
       "      <td>146346</td>\n",
       "      <td>Python</td>\n",
       "      <td>51102</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039520</td>\n",
       "      <td>youtubedl</td>\n",
       "      <td>Commandline program download videos YouTubecom...</td>\n",
       "      <td>https://api.github.com/repos/ytdl-org/youtube-dl</td>\n",
       "      <td>126899</td>\n",
       "      <td>Python</td>\n",
       "      <td>9785</td>\n",
       "      <td>4263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                name  \\\n",
       "0   54346799          publicapis   \n",
       "1   83222441  systemdesignprimer   \n",
       "2   63476337              Python   \n",
       "3  123458551       Python100Days   \n",
       "4    1039520           youtubedl   \n",
       "\n",
       "                                         description  \\\n",
       "0                          collective list free APIs   \n",
       "1  Learn design largescale systems Prep system de...   \n",
       "2                      Algorithms implemented Python   \n",
       "3                                         Python 100   \n",
       "4  Commandline program download videos YouTubecom...   \n",
       "\n",
       "                                                 url   stars language  \\\n",
       "0  https://api.github.com/repos/public-apis/publi...  278839   Python   \n",
       "1  https://api.github.com/repos/donnemartin/syste...  245714   Python   \n",
       "2  https://api.github.com/repos/TheAlgorithms/Python  175617   Python   \n",
       "3  https://api.github.com/repos/jackfrued/Python-...  146346   Python   \n",
       "4   https://api.github.com/repos/ytdl-org/youtube-dl  126899   Python   \n",
       "\n",
       "   num_forks  open_issues  \n",
       "0      31309          237  \n",
       "1      42633          415  \n",
       "2      43858          224  \n",
       "3      51102          706  \n",
       "4       9785         4263  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('../Data/clean/mostStarredReposCleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "name           0\n",
       "description    0\n",
       "url            0\n",
       "stars          0\n",
       "language       0\n",
       "num_forks      0\n",
       "open_issues    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1133 entries, 0 to 1145\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           1133 non-null   int64 \n",
      " 1   name         1133 non-null   object\n",
      " 2   description  1133 non-null   object\n",
      " 3   url          1133 non-null   object\n",
      " 4   stars        1133 non-null   int64 \n",
      " 5   language     1133 non-null   object\n",
      " 6   num_forks    1133 non-null   int64 \n",
      " 7   open_issues  1133 non-null   int64 \n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 79.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>stars</th>\n",
       "      <th>num_forks</th>\n",
       "      <th>open_issues</th>\n",
       "      <th>language_C</th>\n",
       "      <th>language_C#</th>\n",
       "      <th>language_C++</th>\n",
       "      <th>...</th>\n",
       "      <th>language_Kotlin</th>\n",
       "      <th>language_Nix</th>\n",
       "      <th>language_PHP</th>\n",
       "      <th>language_Python</th>\n",
       "      <th>language_Ruby</th>\n",
       "      <th>language_Rust</th>\n",
       "      <th>language_Scala</th>\n",
       "      <th>language_Shell</th>\n",
       "      <th>language_Swift</th>\n",
       "      <th>language_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54346799</td>\n",
       "      <td>publicapis</td>\n",
       "      <td>collective list free APIs</td>\n",
       "      <td>https://api.github.com/repos/public-apis/publi...</td>\n",
       "      <td>278839</td>\n",
       "      <td>31309</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83222441</td>\n",
       "      <td>systemdesignprimer</td>\n",
       "      <td>Learn design largescale systems Prep system de...</td>\n",
       "      <td>https://api.github.com/repos/donnemartin/syste...</td>\n",
       "      <td>245714</td>\n",
       "      <td>42633</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63476337</td>\n",
       "      <td>Python</td>\n",
       "      <td>Algorithms implemented Python</td>\n",
       "      <td>https://api.github.com/repos/TheAlgorithms/Python</td>\n",
       "      <td>175617</td>\n",
       "      <td>43858</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123458551</td>\n",
       "      <td>Python100Days</td>\n",
       "      <td>Python 100</td>\n",
       "      <td>https://api.github.com/repos/jackfrued/Python-...</td>\n",
       "      <td>146346</td>\n",
       "      <td>51102</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039520</td>\n",
       "      <td>youtubedl</td>\n",
       "      <td>Commandline program download videos YouTubecom...</td>\n",
       "      <td>https://api.github.com/repos/ytdl-org/youtube-dl</td>\n",
       "      <td>126899</td>\n",
       "      <td>9785</td>\n",
       "      <td>4263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                name  \\\n",
       "0   54346799          publicapis   \n",
       "1   83222441  systemdesignprimer   \n",
       "2   63476337              Python   \n",
       "3  123458551       Python100Days   \n",
       "4    1039520           youtubedl   \n",
       "\n",
       "                                         description  \\\n",
       "0                          collective list free APIs   \n",
       "1  Learn design largescale systems Prep system de...   \n",
       "2                      Algorithms implemented Python   \n",
       "3                                         Python 100   \n",
       "4  Commandline program download videos YouTubecom...   \n",
       "\n",
       "                                                 url   stars  num_forks  \\\n",
       "0  https://api.github.com/repos/public-apis/publi...  278839      31309   \n",
       "1  https://api.github.com/repos/donnemartin/syste...  245714      42633   \n",
       "2  https://api.github.com/repos/TheAlgorithms/Python  175617      43858   \n",
       "3  https://api.github.com/repos/jackfrued/Python-...  146346      51102   \n",
       "4   https://api.github.com/repos/ytdl-org/youtube-dl  126899       9785   \n",
       "\n",
       "   open_issues  language_C  language_C#  language_C++  ...  language_Kotlin  \\\n",
       "0          237           0            0             0  ...                0   \n",
       "1          415           0            0             0  ...                0   \n",
       "2          224           0            0             0  ...                0   \n",
       "3          706           0            0             0  ...                0   \n",
       "4         4263           0            0             0  ...                0   \n",
       "\n",
       "   language_Nix  language_PHP  language_Python  language_Ruby  language_Rust  \\\n",
       "0             0             0                1              0              0   \n",
       "1             0             0                1              0              0   \n",
       "2             0             0                1              0              0   \n",
       "3             0             0                1              0              0   \n",
       "4             0             0                1              0              0   \n",
       "\n",
       "   language_Scala  language_Shell  language_Swift  language_TypeScript  \n",
       "0               0               0               0                    0  \n",
       "1               0               0               0                    0  \n",
       "2               0               0               0                    0  \n",
       "3               0               0               0                    0  \n",
       "4               0               0               0                    0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding of categorical variables\n",
    "categorical_columns = ['language']\n",
    "df = pd.get_dummies(df, columns=categorical_columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing textual data and converting them to pytorch tensors for later model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1133, 1000])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df['description'] = df['description'].fillna('').astype(str)\n",
    "\n",
    "# Initializing TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# Applying TF-IDF to 'description' column\n",
    "tfidf_description = tfidf_vectorizer.fit_transform(df['description']).toarray()\n",
    "\n",
    "# Converting TF-IDF results to PyTorch tensors\n",
    "tfidf_description_tensor = torch.tensor(tfidf_description, dtype=torch.float32)\n",
    "\n",
    "# Displaying the shape of the tensors\n",
    "tfidf_description_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      stars  num_forks  open_issues\n",
       " 0  0.727603   0.350101     0.008399\n",
       " 1  0.641047   0.476739     0.014707\n",
       " 2  0.457884   0.490438     0.007938\n",
       " 3  0.381399   0.571449     0.025020\n",
       " 4  0.330584   0.109394     0.151079,\n",
       " torch.Size([1133, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Selecting numerical features for normalization\n",
    "numerical_features = ['stars', 'num_forks', 'open_issues']\n",
    "\n",
    "# Check for NaNs in numerical features\n",
    "if df[numerical_features].isnull().values.any():\n",
    "    print(\"NaN values found in numerical features, handling them...\")\n",
    "    # Handle NaNs here, e.g., df[numerical_features].fillna(df[numerical_features].mean(), inplace=True)\n",
    "\n",
    "# Initializing the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Applying normalization to the numerical features\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Check if NaNs are introduced by the scaler\n",
    "if np.isnan(df[numerical_features].values).any():\n",
    "    print(\"NaN values introduced after scaling\")\n",
    "\n",
    "# Converting the normalized data to PyTorch tensors\n",
    "normalized_features_tensor = torch.tensor(df[numerical_features].values, dtype=torch.float32)\n",
    "\n",
    "# Displaying the first few rows of the normalized dataframe and the shape of the tensor\n",
    "df[numerical_features].head(), normalized_features_tensor.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulated User Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simulated user-repo interaction matrix\n",
    "simulated_users = {'user1': 'language_Python', 'user2': 'language_JavaScript', 'user3': 'language_Java'}\n",
    "\n",
    "# Initialize the interaction matrix as a NumPy array of zeros\n",
    "num_rows = df.shape[0]\n",
    "interaction_matrix_np = np.zeros((num_rows, len(simulated_users)))\n",
    "\n",
    "# Populate the interaction matrix using NumPy\n",
    "user_columns = [simulated_users[user] for user in simulated_users]\n",
    "for i, column in enumerate(user_columns):\n",
    "    interaction_matrix_np[:, i] = df[column].values\n",
    "\n",
    "# Convert the NumPy array to a Pandas DataFrame (optional, for verification)\n",
    "interaction_matrix_df = pd.DataFrame(interaction_matrix_np, columns=simulated_users.keys())\n",
    "\n",
    "# Convert the interaction matrix to a PyTorch tensor\n",
    "interaction_matrix_tensor = torch.tensor(interaction_matrix_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume normalized_features_tensor is a tensor of your numerical features\n",
    "# Concatenate all features (content, collaborative, numerical) into one tensor\n",
    "all_features = torch.cat((tfidf_description_tensor, normalized_features_tensor, interaction_matrix_tensor), dim=1)\n",
    "\n",
    "# Create a dummy target variable (This should be replaced with your actual target variable)\n",
    "target = torch.randint(0, 2, (all_features.shape[0], 1), dtype=torch.float)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    all_features, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HybridRecommendationModel(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden=128):\n",
    "        super(HybridRecommendationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = nn.Linear(num_hidden, 1)\n",
    "        \n",
    "        # Weight initialization\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.output.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# Number of features in your dataset\n",
    "num_features = features_train.shape[1]\n",
    "\n",
    "# Instantiate the model\n",
    "model = HybridRecommendationModel(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting input tensors to float32\n",
    "features_train = features_train.float()\n",
    "features_test = features_test.float()\n",
    "target_train = target_train.float()\n",
    "target_test = target_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6832929849624634\n",
      "Epoch [2/100], Loss: 0.6824767589569092\n",
      "Epoch [3/100], Loss: 0.6811962127685547\n",
      "Epoch [4/100], Loss: 0.6794062852859497\n",
      "Epoch [5/100], Loss: 0.6770769953727722\n",
      "Epoch [6/100], Loss: 0.6741318106651306\n",
      "Epoch [7/100], Loss: 0.6705149412155151\n",
      "Epoch [8/100], Loss: 0.6660303473472595\n",
      "Epoch [9/100], Loss: 0.6605780720710754\n",
      "Epoch [10/100], Loss: 0.6537641882896423\n",
      "Epoch [11/100], Loss: 0.6452128887176514\n",
      "Epoch [12/100], Loss: 0.6345345973968506\n",
      "Epoch [13/100], Loss: 0.6213228106498718\n",
      "Epoch [14/100], Loss: 0.6049414873123169\n",
      "Epoch [15/100], Loss: 0.5851572751998901\n",
      "Epoch [16/100], Loss: 0.5617567300796509\n",
      "Epoch [17/100], Loss: 0.5344243049621582\n",
      "Epoch [18/100], Loss: 0.503656804561615\n",
      "Epoch [19/100], Loss: 0.4703712463378906\n",
      "Epoch [20/100], Loss: 0.4345739483833313\n",
      "Epoch [21/100], Loss: 0.3959755599498749\n",
      "Epoch [22/100], Loss: 0.35644999146461487\n",
      "Epoch [23/100], Loss: 0.3180052638053894\n",
      "Epoch [24/100], Loss: 0.28094252943992615\n",
      "Epoch [25/100], Loss: 0.2466808557510376\n",
      "Epoch [26/100], Loss: 0.2161864936351776\n",
      "Epoch [27/100], Loss: 0.18979930877685547\n",
      "Epoch [28/100], Loss: 0.16650518774986267\n",
      "Epoch [29/100], Loss: 0.1460687220096588\n",
      "Epoch [30/100], Loss: 0.128379225730896\n",
      "Epoch [31/100], Loss: 0.11325530707836151\n",
      "Epoch [32/100], Loss: 0.10017572343349457\n",
      "Epoch [33/100], Loss: 0.08887674659490585\n",
      "Epoch [34/100], Loss: 0.07914073765277863\n",
      "Epoch [35/100], Loss: 0.07074331492185593\n",
      "Epoch [36/100], Loss: 0.06350991874933243\n",
      "Epoch [37/100], Loss: 0.057334206998348236\n",
      "Epoch [38/100], Loss: 0.05199456214904785\n",
      "Epoch [39/100], Loss: 0.0473841167986393\n",
      "Epoch [40/100], Loss: 0.04338151216506958\n",
      "Epoch [41/100], Loss: 0.03985460847616196\n",
      "Epoch [42/100], Loss: 0.03677528351545334\n",
      "Epoch [43/100], Loss: 0.034091126173734665\n",
      "Epoch [44/100], Loss: 0.03170870989561081\n",
      "Epoch [45/100], Loss: 0.0296328067779541\n",
      "Epoch [46/100], Loss: 0.027832794934511185\n",
      "Epoch [47/100], Loss: 0.026209931820631027\n",
      "Epoch [48/100], Loss: 0.024801334366202354\n",
      "Epoch [49/100], Loss: 0.023535627871751785\n",
      "Epoch [50/100], Loss: 0.02241375856101513\n",
      "Epoch [51/100], Loss: 0.02141154743731022\n",
      "Epoch [52/100], Loss: 0.020526492968201637\n",
      "Epoch [53/100], Loss: 0.019746404141187668\n",
      "Epoch [54/100], Loss: 0.019038284197449684\n",
      "Epoch [55/100], Loss: 0.01842874102294445\n",
      "Epoch [56/100], Loss: 0.017863130196928978\n",
      "Epoch [57/100], Loss: 0.017362672835588455\n",
      "Epoch [58/100], Loss: 0.016940074041485786\n",
      "Epoch [59/100], Loss: 0.016540735960006714\n",
      "Epoch [60/100], Loss: 0.01620304211974144\n",
      "Epoch [61/100], Loss: 0.01587642915546894\n",
      "Epoch [62/100], Loss: 0.015584491193294525\n",
      "Epoch [63/100], Loss: 0.015318386256694794\n",
      "Epoch [64/100], Loss: 0.015120076015591621\n",
      "Epoch [65/100], Loss: 0.01490106713026762\n",
      "Epoch [66/100], Loss: 0.01472393237054348\n",
      "Epoch [67/100], Loss: 0.014565018936991692\n",
      "Epoch [68/100], Loss: 0.014420071616768837\n",
      "Epoch [69/100], Loss: 0.014296358451247215\n",
      "Epoch [70/100], Loss: 0.014192293398082256\n",
      "Epoch [71/100], Loss: 0.014118695631623268\n",
      "Epoch [72/100], Loss: 0.014017772860825062\n",
      "Epoch [73/100], Loss: 0.01393813081085682\n",
      "Epoch [74/100], Loss: 0.013898380100727081\n",
      "Epoch [75/100], Loss: 0.013824904337525368\n",
      "Epoch [76/100], Loss: 0.013771278783679008\n",
      "Epoch [77/100], Loss: 0.013699944131076336\n",
      "Epoch [78/100], Loss: 0.013688298873603344\n",
      "Epoch [79/100], Loss: 0.013631366193294525\n",
      "Epoch [80/100], Loss: 0.013574028387665749\n",
      "Epoch [81/100], Loss: 0.01354883797466755\n",
      "Epoch [82/100], Loss: 0.01352288294583559\n",
      "Epoch [83/100], Loss: 0.013469105586409569\n",
      "Epoch [84/100], Loss: 0.013445417396724224\n",
      "Epoch [85/100], Loss: 0.013413402251899242\n",
      "Epoch [86/100], Loss: 0.0133743304759264\n",
      "Epoch [87/100], Loss: 0.013324801810085773\n",
      "Epoch [88/100], Loss: 0.013308823108673096\n",
      "Epoch [89/100], Loss: 0.013283124193549156\n",
      "Epoch [90/100], Loss: 0.013245654292404652\n",
      "Epoch [91/100], Loss: 0.013235610909759998\n",
      "Epoch [92/100], Loss: 0.013197881169617176\n",
      "Epoch [93/100], Loss: 0.01316388975828886\n",
      "Epoch [94/100], Loss: 0.013143549673259258\n",
      "Epoch [95/100], Loss: 0.013102593831717968\n",
      "Epoch [96/100], Loss: 0.01309831440448761\n",
      "Epoch [97/100], Loss: 0.01305293757468462\n",
      "Epoch [98/100], Loss: 0.013039548881351948\n",
      "Epoch [99/100], Loss: 0.013011937029659748\n",
      "Epoch [100/100], Loss: 0.012979413382709026\n"
     ]
    }
   ],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 32  # Adjust based on your dataset\n",
    "# Gradient clipping value\n",
    "clip_value = 1.0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    loss = None  # Initialize loss to None or a default value\n",
    "    for i in range(0, len(features_train), batch_size):\n",
    "        batch_features = features_train[i:i + batch_size]\n",
    "        batch_targets = target_train[i:i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "        outputs = torch.clamp(outputs, 0, 1)\n",
    "\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Check if loss is available before printing\n",
    "    if loss is not None:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "    else:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss calculation was skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.9806822538375854\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(features_test)\n",
    "    test_loss = criterion(test_outputs, target_test)\n",
    "print(f\"Test Loss: {test_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IEML",
   "language": "python",
   "name": "ieml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
