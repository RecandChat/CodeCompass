{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from codecompasslib.API.drive_operations import download_csv_as_pd_dataframe, get_creds_drive\n",
    "from codecompasslib.models.model_diff_repos import load_word2vec_model, vectorize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(full_data_folder_id: str, full_data_embedded_folder_id: str) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    Load the data from the Google Drive\n",
    "    :return: The non-embedded and embedded datasets\n",
    "    \"\"\"\n",
    "    DRIVE_ID = \"0AL1DtB4TdEWdUk9PVA\"\n",
    "    DATA_FOLDER = \"13JitBJQLNgMvFwx4QJcvrmDwKOYAShVx\"\n",
    "\n",
    "    creds = get_creds_drive()\n",
    "    df_non_embedded: DataFrame = download_csv_as_pd_dataframe(creds=creds, file_id=full_data_folder_id)\n",
    "    df_embedded: DataFrame = download_csv_as_pd_dataframe(creds=creds, file_id=full_data_embedded_folder_id)\n",
    "\n",
    "    # Having data locally works much faster than retrieving from drive. Uncomment the following lines to use local data\n",
    "    # df_non_embedded = pd.read_csv('codecompasslib/models/data_full.csv')\n",
    "    # df_embedded = pd.read_csv('codecompasslib/models/df_embedded_combined.csv')\n",
    "\n",
    "    print(\"Data loaded\")\n",
    "    return df_non_embedded, df_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mirandadrummond/VSCode/CodeCompass/codecompasslib/models/examples/../../../secrets/token.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m full_data_folder_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Qiy9u03hUthqaoBDr4VQqhKwtLJ2O3Yd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m full_data_embedded_folder_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m139wi78iRzhwGZwxmI5WALoYocR-Rk9By\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df_non_embedded, df_embedded \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_data_folder_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_data_embedded_folder_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(full_data_folder_id, full_data_embedded_folder_id)\u001b[0m\n\u001b[1;32m      6\u001b[0m DRIVE_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0AL1DtB4TdEWdUk9PVA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m DATA_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m13JitBJQLNgMvFwx4QJcvrmDwKOYAShVx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m creds \u001b[38;5;241m=\u001b[39m \u001b[43mget_creds_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df_non_embedded: DataFrame \u001b[38;5;241m=\u001b[39m download_csv_as_pd_dataframe(creds\u001b[38;5;241m=\u001b[39mcreds, file_id\u001b[38;5;241m=\u001b[39mfull_data_folder_id)\n\u001b[1;32m     11\u001b[0m df_embedded: DataFrame \u001b[38;5;241m=\u001b[39m download_csv_as_pd_dataframe(creds\u001b[38;5;241m=\u001b[39mcreds, file_id\u001b[38;5;241m=\u001b[39mfull_data_embedded_folder_id)\n",
      "File \u001b[0;32m~/VSCode/CodeCompass/codecompasslib/models/examples/../../../codecompasslib/API/drive_operations.py:24\u001b[0m, in \u001b[0;36mget_creds_drive\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_creds_drive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Credentials:\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Get the credentials for the Google Drive API\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    :return: None\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     creds: Credentials \u001b[38;5;241m=\u001b[39m \u001b[43mCredentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_authorized_user_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUTER_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/secrets/token.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSCOPES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m creds \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m creds\u001b[38;5;241m.\u001b[39mvalid:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m creds \u001b[38;5;129;01mand\u001b[39;00m creds\u001b[38;5;241m.\u001b[39mexpired \u001b[38;5;129;01mand\u001b[39;00m creds\u001b[38;5;241m.\u001b[39mrefresh_token:\n",
      "File \u001b[0;32m~/VSCode/CodeCompass/.venv/lib/python3.11/site-packages/google/oauth2/credentials.py:537\u001b[0m, in \u001b[0;36mCredentials.from_authorized_user_file\u001b[0;34m(cls, filename, scopes)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_authorized_user_file\u001b[39m(\u001b[38;5;28mcls\u001b[39m, filename, scopes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a Credentials instance from an authorized user json file.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;124;03m        ValueError: If the file is not in the expected format.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m    538\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_authorized_user_info(data, scopes)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mirandadrummond/VSCode/CodeCompass/codecompasslib/models/examples/../../../secrets/token.json'"
     ]
    }
   ],
   "source": [
    "full_data_folder_id = '1Qiy9u03hUthqaoBDr4VQqhKwtLJ2O3Yd'\n",
    "full_data_embedded_folder_id = '139wi78iRzhwGZwxmI5WALoYocR-Rk9By'\n",
    "\n",
    "df_non_embedded, df_embedded = load_data(full_data_folder_id, full_data_embedded_folder_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(df_non_embedded):\n",
    "    \"\"\"\n",
    "    Load and clean the dataset from a specified filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): The file path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = df_non_embedded\n",
    "\n",
    "    # Delete missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Delete columns that are not needed\n",
    "    columns_to_drop = [\n",
    "        'is_archived', 'is_disabled', 'is_template', 'has_projects',  \n",
    "        'owner_type', 'has_pages', 'has_wiki', \n",
    "        'has_issues', 'has_downloads', 'is_fork'\n",
    "    ]\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Handling missing values in text columns\n",
    "    df['description'].fillna('', inplace=True)\n",
    "    df['name'].fillna('', inplace=True)\n",
    "    df['language'].fillna('', inplace=True)\n",
    "\n",
    "    # Drop duplicates with name\n",
    "    df.drop_duplicates(subset='name', keep='first', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data(df_non_embedded)\n",
    "\n",
    "# count unique languges\n",
    "df['language'].nunique()\n",
    "\n",
    "# Create list of unique languages with _ prefix\n",
    "languages = ['_' + language for language in df['language'].unique()]\n",
    "\n",
    "# one hot encode the languages and don't include the language prefix\n",
    "df = pd.get_dummies(df, columns=['language'], prefix='')\n",
    "\n",
    "# Turn df into a repo specific df with owner_user as a unique identifier, appending description and keeping 1 if any of the languages are present in at least one repo\n",
    "\n",
    "# Create a dictionary for aggregation\n",
    "aggregation_dict = {\n",
    "    'name': lambda x: list(x),\n",
    "    'description': lambda x: list(x)\n",
    "}\n",
    "\n",
    "# Add columns for languages\n",
    "for lang in languages:\n",
    "    aggregation_dict[lang] = 'max'\n",
    "\n",
    "# Group by 'owner_user' and aggregate\n",
    "user_df = df.groupby('owner_user').agg(aggregation_dict).reset_index()\n",
    "\n",
    "# Display the first few rows of the resulting DataFrame\n",
    "user_df.head()\n",
    "\n",
    "# first we turn list of names and descriptions into a single string\n",
    "user_df['name'] = user_df['name'].apply(lambda x: ' '.join(str(i) for i in x) if isinstance(x, list) else '')\n",
    "user_df['description'] = user_df['description'].apply(lambda x: ' '.join(str(i) for i in x) if isinstance(x, list) else '')\n",
    "user_df.head()\n",
    "\n",
    "word_vect = load_word2vec_model\n",
    "\n",
    "# Text preprocessing\n",
    "embedded_user_df = user_df.copy()\n",
    "embedded_user_df['name'] = user_df['name'].fillna('')  \n",
    "embedded_user_df['description'] = user_df['description'].fillna('')\n",
    "\n",
    "embedded_user_df['name_vector'] = embedded_user_df['name'].apply(vectorize_text)\n",
    "embedded_user_df['description_vector'] = embedded_user_df['description'].apply(vectorize_text)\n",
    "embedded_user_df\n",
    "# embedded_user_df.drop(['name', 'description', 'owner_user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform df into something that KNN can use. To be more specific, into a feature matrix\n",
    "# Create a list of all the vectors\n",
    "vectors = []\n",
    "repo_df = embedded_user_df * 1 # convert all boolean values in repo_df to 0 or 1\n",
    "\n",
    "for row in repo_df.index: \n",
    "    vector = []\n",
    "    for columns in ['name_vector', 'description_vector']:\n",
    "        if type(repo_df.at[row, columns]) == np.ndarray:\n",
    "            for element in repo_df.at[row, columns]:\n",
    "                vector.append(element)\n",
    "        else: vector.append(repo_df.at[row, columns])\n",
    "    vectors.append(vector)\n",
    "\n",
    "    # Train Nearest Neighbors Model\n",
    "k = 5  # Number of neighbors to find\n",
    "nn_model = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "nn_model.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "\n",
    "target_user = 21\n",
    "# neighbors excluding the target user\n",
    "neighbors = nn_model.kneighbors([vectors[target_user]], return_distance=False)[0][1:]\n",
    "neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
