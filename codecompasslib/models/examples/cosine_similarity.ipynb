{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from codecompasslib.API.drive_operations import download_csv_as_pd_dataframe, get_creds_drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similairty Model\n",
    "\n",
    "This model utilizes the cosine similarity between the query and the documents to rank the documents. The cosine similarity is calculated as follows:\n",
    "\n",
    "- Using NLP and TFIDF, the repository, language and its description are tokenized and vectorized.\n",
    "- The cosine similarity is calculated.\n",
    "- The repos are ranked based on the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(full_data_folder_id: str, full_data_embedded_folder_id: str) -> Tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    Load the data from the Google Drive\n",
    "    :return: The non-embedded and embedded datasets\n",
    "    \"\"\"\n",
    "    DRIVE_ID = \"0AL1DtB4TdEWdUk9PVA\"\n",
    "    DATA_FOLDER = \"13JitBJQLNgMvFwx4QJcvrmDwKOYAShVx\"\n",
    "\n",
    "    creds = get_creds_drive()\n",
    "    df_non_embedded: DataFrame = download_csv_as_pd_dataframe(creds=creds, file_id=full_data_folder_id)\n",
    "    df_embedded: DataFrame = download_csv_as_pd_dataframe(creds=creds, file_id=full_data_embedded_folder_id)\n",
    "\n",
    "    # Having data locally works much faster than retrieving from drive. Uncomment the following lines to use local data\n",
    "    # df_non_embedded = pd.read_csv('codecompasslib/models/data_full.csv')\n",
    "    # df_embedded = pd.read_csv('codecompasslib/models/df_embedded_combined.csv')\n",
    "\n",
    "    print(\"Data loaded\")\n",
    "    return df_non_embedded, df_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_folder_id = '1Qiy9u03hUthqaoBDr4VQqhKwtLJ2O3Yd'\n",
    "full_data_embedded_folder_id = '139wi78iRzhwGZwxmI5WALoYocR-Rk9By'\n",
    "\n",
    "df_non_embedded, df_embedded = load_data(full_data_folder_id, full_data_embedded_folder_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(df_non_embedded):\n",
    "    \"\"\"\n",
    "    Load and clean the dataset from a specified filepath.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): The file path to the dataset.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    df = df_non_embedded\n",
    "\n",
    "    # Delete missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Delete columns that are not needed\n",
    "    columns_to_drop = [\n",
    "        'is_archived', 'is_disabled', 'is_template', 'has_projects',  \n",
    "        'owner_type', 'has_pages', 'has_wiki', \n",
    "        'has_issues', 'has_downloads', 'is_fork'\n",
    "    ]\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Handling missing values in text columns\n",
    "    df['description'].fillna('', inplace=True)\n",
    "    df['name'].fillna('', inplace=True)\n",
    "    df['language'].fillna('', inplace=True)\n",
    "\n",
    "    # Drop duplicates with name\n",
    "    df.drop_duplicates(subset='name', keep='first', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity_scores(df):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity scores for the dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing repository data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the DataFrame with added similarity scores and the TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    # Concatenating the text columns for vectorization\n",
    "    text_data = df['name'] + \" \" + df['description'] + \" \" + df['language']\n",
    "\n",
    "    # Vectorizing the text data using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)\n",
    "\n",
    "    # Calculating cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Average the cosine similarities for each repo\n",
    "    similarity_scores = np.mean(cosine_sim, axis=1)\n",
    "\n",
    "    # Adding the new column to the dataset\n",
    "    df['cosine_similarity_score'] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity_scores(df):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity scores for the dataset.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing repository data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the DataFrame with added similarity scores and the TF-IDF vectorizer.\n",
    "    \"\"\"\n",
    "    # Concatenating the text columns for vectorization\n",
    "    text_data = df['name'] + \" \" + df['description'] + \" \" + df['language']\n",
    "\n",
    "    # Vectorizing the text data using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(text_data)\n",
    "\n",
    "    # Calculating cosine similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # Average the cosine similarities for each repo\n",
    "    similarity_scores = np.mean(cosine_sim, axis=1)\n",
    "\n",
    "    # Adding the new column to the dataset\n",
    "    df['cosine_similarity_score'] = similarity_scores\n",
    "\n",
    "    return df, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_repos(user_preference, df, tfidf_vectorizer, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommend repositories based on user preferences.\n",
    "\n",
    "    Args:\n",
    "        user_preference (str): The user's preferred keywords or phrases.\n",
    "        df (pandas.DataFrame): The DataFrame containing repository data.\n",
    "        tfidf_vectorizer (TfidfVectorizer): The TF-IDF vectorizer used for transforming text data.\n",
    "        top_n (int, optional): Number of top recommendations to return. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing top_n recommended repositories.\n",
    "    \"\"\"\n",
    "    # Vectorize the user preference\n",
    "    user_pref_vector = tfidf_vectorizer.transform([user_preference])\n",
    "\n",
    "    # Calculate cosine similarity with all repositories\n",
    "    cosine_scores = cosine_similarity(user_pref_vector, tfidf_vectorizer.transform(df['name'] + \" \" + df['description'] + \" \" + df['language'])).flatten()\n",
    "\n",
    "    # Get the indices of the repositories with the highest similarity scores\n",
    "    top_indices = np.argsort(cosine_scores)[-top_n:][::-1]\n",
    "\n",
    "    # Select the top n recommended repositories\n",
    "    recommended_repos = df.iloc[top_indices].reset_index(drop=True)\n",
    "\n",
    "    return recommended_repos[['name', 'description', 'language', 'cosine_similarity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df):\n",
    "    \"\"\"\n",
    "    Main function to run the script.\n",
    "    \"\"\"\n",
    "    df, tfidf_vectorizer = calculate_cosine_similarity_scores(df)\n",
    "    user_preference = \"python\"\n",
    "    recommended_repos = recommend_repos(user_preference, df, tfidf_vectorizer, top_n=10)\n",
    "    print(recommended_repos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
