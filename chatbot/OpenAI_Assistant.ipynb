{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install the latest version of the openai library\n",
    "!pip install openai -q --upgrade\n",
    "\n",
    "# imports\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OpenAI key from a file\n",
    "with open('../secrets/openAI_key', 'r') as file:\n",
    "    openAI_key = file.read().replace('\\n', '')\n",
    "\n",
    "# load the github token\n",
    "with open('../secrets/github_token', 'r') as file:\n",
    "    github_token = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the client\n",
    "client = OpenAI(\n",
    "    api_key = openAI_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ASK THE CODE API functions\n",
    "\"\"\"\n",
    "\n",
    "def get_repo_structure(url, branch=None, relativePaths=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_repo_structure_url = \"https://gabriel.askthecode.ai/api/repository/structure\"\n",
    "\n",
    "    # parameters: url(required), branch(optional), relativePaths(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'branch': branch,\n",
    "        'relativePaths': relativePaths\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\",  # Ensure your token is correctly referenced\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_repo_structure_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        structure_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return structure_response\n",
    "    else:\n",
    "        # Return a formatted error message\n",
    "        return f\"Failed to get the repository structure: {response.status_code}, Reason: {response.reason}\"\n",
    "\n",
    "\n",
    "# get repo content\n",
    "def get_repo_content(url, filePaths, branch=None, relativePath=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_repo_content_url = \"https://gabriel.askthecode.ai/api/repository/content\"\n",
    "\n",
    "    # parameters: url(required), filePaths(required), branch(optional), relativePath(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'filePaths': filePaths,\n",
    "        'branch': branch,\n",
    "        'relativePath': relativePath\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_repo_content_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        content_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return content_response\n",
    "    \n",
    "    else:\n",
    "       return f\"Failed to get the repository content: {response.status_code}\"\n",
    "\n",
    "# get repo branches\n",
    "def get_repo_branches(url):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_repo_branches_url = \"https://gabriel.askthecode.ai/api/repository/branch/list\"\n",
    "\n",
    "    # parameters: url(required)\n",
    "    params = {\n",
    "        'url': url\n",
    "    }\n",
    "\n",
    "   # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_repo_branches_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        branches_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return branches_response\n",
    "    else:\n",
    "        return f\"Failed to get the repository branches: {response.status_code}\"\n",
    "    \n",
    "# Get commit history\n",
    "def get_commit_history(url, branch=None, filePath=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_commit_history_url = \"https://gabriel.askthecode.ai/api/repository/commit/history\"\n",
    "\n",
    "    # parameters: url(required), branch(optional), filePath(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'branch': branch,\n",
    "        'filePath': filePath\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_commit_history_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        commit_history_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return commit_history_response\n",
    "    else:\n",
    "        return f\"Failed to get the commit history: {response.status_code}\"\n",
    "    \n",
    "# search repo code\n",
    "def search_repo_code(url, searchKeywords, branch=None, relativePath=None, searchHitLinesCount=None, skipMatchesCount=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    search_repo_code_url = \"https://gabriel.askthecode.ai/api/search/repository/code\"\n",
    "\n",
    "    # parameters: url(required), searchKeywords(required), branch(optional), relativePath(optional), searchHitLinesCount(optional), skipMatchesCount(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'searchKeywords': searchKeywords,\n",
    "        'branch': branch,\n",
    "        'relativePath': relativePath,\n",
    "        'searchHitLinesCount': searchHitLinesCount,\n",
    "        'skipMatchesCount': skipMatchesCount\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(search_repo_code_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        search_code_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return search_code_response\n",
    "    else:\n",
    "        return f\"Failed to search the repository code: {response.status_code}\"\n",
    "\n",
    "# search repo commits\n",
    "def search_repo_commits(url, searchKeywords):\n",
    "    # URL of Askthecode API endpoint\n",
    "    search_repo_commits_url = \"https://gabriel.askthecode.ai/api/search/repository/commits\"\n",
    "\n",
    "    # parameters: url(required), searchKeywords(required)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'searchKeywords': searchKeywords\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(search_repo_commits_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        search_commits_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return search_commits_response\n",
    "    else:\n",
    "        return f\"Failed to search the repository commits: {response.status_code}\"\n",
    "    \n",
    "def find_repos(searchKeywords, language=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    find_repos_url = \"https://gabriel.askthecode.ai/api/search/repository\"\n",
    "\n",
    "    # parameters: searchKeywords(required), language(optional)\n",
    "    params = {\n",
    "        'searchKeywords': searchKeywords,\n",
    "        'language': language\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(find_repos_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        find_repos_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return find_repos_response\n",
    "    else:\n",
    "        return f\"Failed to find repositories: {response.status_code}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the structure of the repository:\n",
      "{'branchName': 'main', 'files': ['.devcontainer/Dockerfile', '.devcontainer/devcontainer.json', '.github/.codecov.yml', '.github/CODEOWNERS', '.github/ISSUE_TEMPLATE.md', '.github/ISSUE_TEMPLATE/bug_report.md', '.github/ISSUE_TEMPLATE/feature_request.md', '.github/ISSUE_TEMPLATE/general-ask.md', '.github/PULL_REQUEST_TEMPLATE.md', '.github/actions/azureml-test/action.yml', '.github/actions/get-test-groups/action.yml', '.github/workflows/azureml-cpu-nightly.yml', '.github/workflows/azureml-gpu-nightly.yml', '.github/workflows/azureml-release-pipeline.yml', '.github/workflows/azureml-spark-nightly.yml', '.github/workflows/azureml-unit-tests.yml', '.github/workflows/sarplus.yml', '.github/workflows/update_documentation.yml', 'AUTHORS.md', 'CODE_OF_CONDUCT.md', 'CONTRIBUTING.md', 'GLOSSARY.md', 'LICENSE', 'MANIFEST.in', 'NEWS.md', 'README.md', 'SECURITY.md', 'SETUP.md', 'contrib/README.md', 'contrib/azureml_designer_modules/README.md', 'contrib/azureml_designer_modules/entries/map_entry.py', 'contrib/azureml_designer_modules/entries/ndcg_entry.py', 'contrib/azureml_designer_modules/entries/precision_at_k_entry.py', 'contrib/azureml_designer_modules/entries/recall_at_k_entry.py', 'contrib/azureml_designer_modules/entries/score_sar_entry.py', 'contrib/azureml_designer_modules/entries/stratified_splitter_entry.py', 'contrib/azureml_designer_modules/entries/train_sar_entry.py', 'contrib/azureml_designer_modules/module_specs/map.yaml', 'contrib/azureml_designer_modules/module_specs/ndcg.yaml', 'contrib/azureml_designer_modules/module_specs/precision_at_k.yaml', 'contrib/azureml_designer_modules/module_specs/recall_at_k.yaml', 'contrib/azureml_designer_modules/module_specs/sar_conda.yaml', 'contrib/azureml_designer_modules/module_specs/sar_score.yaml', 'contrib/azureml_designer_modules/module_specs/sar_train.yaml', 'contrib/azureml_designer_modules/module_specs/stratified_splitter.yaml', 'contrib/sarplus/DEVELOPMENT.md', 'contrib/sarplus/README.md', 'contrib/sarplus/VERSION', 'contrib/sarplus/python/.flake8', 'contrib/sarplus/python/README.md', 'contrib/sarplus/python/pyproject.toml', 'contrib/sarplus/python/pysarplus/SARModel.py', 'contrib/sarplus/python/pysarplus/SARPlus.py', 'contrib/sarplus/python/pysarplus/__init__.py', 'contrib/sarplus/python/setup.py', 'contrib/sarplus/python/src/pysarplus.cpp', 'contrib/sarplus/python/tests/conftest.py', 'contrib/sarplus/python/tests/sample-input.txt', 'contrib/sarplus/python/tests/test_pyspark_sar.py', 'contrib/sarplus/scala/build.sbt', 'contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/compat/spark/since3p2defvisible.scala', 'contrib/sarplus/scala/project/Utils.scala', 'contrib/sarplus/scala/project/build.properties', 'contrib/sarplus/scala/project/plugins.sbt', 'contrib/sarplus/scala/python/pysarplus_dummy/__init__.py', 'contrib/sarplus/scala/python/setup.py', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/DefaultSource.scala', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriter.scala', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriterFactory.scala', 'contrib/sarplus/scala/src/test/scala/com/microsoft/sarplus/SARCacheOutputWriterSpec.scala', 'docs/_config.yml', 'docs/_toc.yml', 'docs/datasets.rst', 'docs/evaluation.rst', 'docs/intro.md', 'docs/models.rst', 'docs/requirements-doc.txt', 'docs/tuning.rst', 'docs/utils.rst', 'examples/00_quick_start/README.md', 'examples/00_quick_start/als_movielens.ipynb', 'examples/00_quick_start/dkn_MIND.ipynb', 'examples/00_quick_start/fastai_movielens.ipynb', 'examples/00_quick_start/geoimc_movielens.ipynb', 'examples/00_quick_start/lightgbm_tinycriteo.ipynb', 'examples/00_quick_start/lstur_MIND.ipynb', 'examples/00_quick_start/naml_MIND.ipynb', 'examples/00_quick_start/ncf_movielens.ipynb', 'examples/00_quick_start/npa_MIND.ipynb', 'examples/00_quick_start/nrms_MIND.ipynb', 'examples/00_quick_start/rbm_movielens.ipynb', 'examples/00_quick_start/rlrmc_movielens.ipynb', 'examples/00_quick_start/sar_movielens.ipynb', 'examples/00_quick_start/sar_movielens_with_azureml.ipynb', 'examples/00_quick_start/sar_movieratings_with_azureml_designer.ipynb', 'examples/00_quick_start/sasrec_amazon.ipynb', 'examples/00_quick_start/sequential_recsys_amazondataset.ipynb', 'examples/00_quick_start/tfidf_covid.ipynb', 'examples/00_quick_start/wide_deep_movielens.ipynb', 'examples/00_quick_start/xdeepfm_criteo.ipynb', 'examples/01_prepare_data/README.md', 'examples/01_prepare_data/data_split.ipynb', 'examples/01_prepare_data/data_transform.ipynb', 'examples/01_prepare_data/mind_utils.ipynb', 'examples/01_prepare_data/wikidata_knowledge_graph.ipynb', 'examples/02_model_collaborative_filtering/README.md', 'examples/02_model_collaborative_filtering/als_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/baseline_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/cornac_bivae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/cornac_bpr_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/fm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/lightfm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/lightgcn_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/multi_vae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/rbm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/sar_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/surprise_svd_deep_dive.ipynb', 'examples/02_model_content_based_filtering/README.md', 'examples/02_model_content_based_filtering/dkn_deep_dive.ipynb', 'examples/02_model_content_based_filtering/mmlspark_lightgbm_criteo.ipynb', 'examples/02_model_content_based_filtering/vowpal_wabbit_deep_dive.ipynb', 'examples/03_evaluate/README.md', 'examples/03_evaluate/als_movielens_diversity_metrics.ipynb', 'examples/03_evaluate/evaluation.ipynb', 'examples/04_model_select_and_optimize/README.md', 'examples/04_model_select_and_optimize/azureml_hyperdrive_surprise_svd.ipynb', 'examples/04_model_select_and_optimize/azureml_hyperdrive_wide_and_deep.ipynb', 'examples/04_model_select_and_optimize/nni_ncf.ipynb', 'examples/04_model_select_and_optimize/nni_surprise_svd.ipynb', 'examples/04_model_select_and_optimize/train_scripts/svd_training.py', 'examples/04_model_select_and_optimize/train_scripts/wide_deep_training.py', 'examples/04_model_select_and_optimize/tuning_spark_als.ipynb', 'examples/05_operationalize/README.md', 'examples/05_operationalize/aks_locust_load_test.ipynb', 'examples/05_operationalize/als_movie_o16n.ipynb', 'examples/05_operationalize/lightgbm_criteo_o16n.ipynb', 'examples/06_benchmarks/README.md', 'examples/06_benchmarks/benchmark_utils.py', 'examples/06_benchmarks/movielens.ipynb', 'examples/07_tutorials/KDD2020-tutorial/README.md', 'examples/07_tutorials/KDD2020-tutorial/dkn.yaml', 'examples/07_tutorials/KDD2020-tutorial/lightgcn.yaml', 'examples/07_tutorials/KDD2020-tutorial/pandas-subgraph-local-samples.ipynb', 'examples/07_tutorials/KDD2020-tutorial/reco_cpu_kdd.yaml', 'examples/07_tutorials/KDD2020-tutorial/reco_gpu_kdd.yaml', 'examples/07_tutorials/KDD2020-tutorial/run_transE.sh', 'examples/07_tutorials/KDD2020-tutorial/step1_data_preparation.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step2_pretraining-embeddings.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step3_run_dkn.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step4_run_dkn_item2item.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step5_run_lightgcn.ipynb', 'examples/07_tutorials/KDD2020-tutorial/utils/PandasMagClass.py', 'examples/07_tutorials/KDD2020-tutorial/utils/data_helper.py', 'examples/07_tutorials/KDD2020-tutorial/utils/general.py', 'examples/07_tutorials/KDD2020-tutorial/utils/task_helper.py', 'examples/README.md', 'examples/run_notebook_on_azureml.ipynb', 'examples/template.ipynb', 'pyproject.toml', 'recommenders/README.md', 'recommenders/__init__.py', 'recommenders/datasets/__init__.py', 'recommenders/datasets/amazon_reviews.py', 'recommenders/datasets/cosmos_cli.py', 'recommenders/datasets/covid_utils.py', 'recommenders/datasets/criteo.py', 'recommenders/datasets/download_utils.py', 'recommenders/datasets/mind.py', 'recommenders/datasets/movielens.py', 'recommenders/datasets/pandas_df_utils.py', 'recommenders/datasets/python_splitters.py', 'recommenders/datasets/spark_splitters.py', 'recommenders/datasets/sparse.py', 'recommenders/datasets/split_utils.py', 'recommenders/datasets/wikidata.py', 'recommenders/evaluation/__init__.py', 'recommenders/evaluation/python_evaluation.py', 'recommenders/evaluation/spark_evaluation.py', 'recommenders/models/__init__.py', 'recommenders/models/cornac/__init__.py', 'recommenders/models/cornac/cornac_utils.py', 'recommenders/models/deeprec/DataModel/ImplicitCF.py', 'recommenders/models/deeprec/DataModel/__init__.py', 'recommenders/models/deeprec/__init__.py', 'recommenders/models/deeprec/config/asvd.yaml', 'recommenders/models/deeprec/config/caser.yaml', 'recommenders/models/deeprec/config/gru.yaml', 'recommenders/models/deeprec/config/lightgcn.yaml', 'recommenders/models/deeprec/config/nextitnet.yaml', 'recommenders/models/deeprec/config/sli_rec.yaml', 'recommenders/models/deeprec/config/sum.yaml', 'recommenders/models/deeprec/deeprec_utils.py', 'recommenders/models/deeprec/io/__init__.py', 'recommenders/models/deeprec/io/dkn_item2item_iterator.py', 'recommenders/models/deeprec/io/dkn_iterator.py', 'recommenders/models/deeprec/io/iterator.py', 'recommenders/models/deeprec/io/nextitnet_iterator.py', 'recommenders/models/deeprec/io/sequential_iterator.py', 'recommenders/models/deeprec/models/__init__.py', 'recommenders/models/deeprec/models/base_model.py', 'recommenders/models/deeprec/models/dkn.py', 'recommenders/models/deeprec/models/dkn_item2item.py', 'recommenders/models/deeprec/models/graphrec/__init__.py', 'recommenders/models/deeprec/models/graphrec/lightgcn.py', 'recommenders/models/deeprec/models/sequential/__init__.py', 'recommenders/models/deeprec/models/sequential/asvd.py', 'recommenders/models/deeprec/models/sequential/caser.py', 'recommenders/models/deeprec/models/sequential/gru.py', 'recommenders/models/deeprec/models/sequential/nextitnet.py', 'recommenders/models/deeprec/models/sequential/rnn_cell_implement.py', 'recommenders/models/deeprec/models/sequential/sequential_base_model.py', 'recommenders/models/deeprec/models/sequential/sli_rec.py', 'recommenders/models/deeprec/models/sequential/sum.py', 'recommenders/models/deeprec/models/sequential/sum_cells.py', 'recommenders/models/deeprec/models/xDeepFM.py', 'recommenders/models/fastai/__init__.py', 'recommenders/models/fastai/fastai_utils.py', 'recommenders/models/geoimc/__init__.py', 'recommenders/models/geoimc/geoimc_algorithm.py', 'recommenders/models/geoimc/geoimc_data.py', 'recommenders/models/geoimc/geoimc_predict.py', 'recommenders/models/geoimc/geoimc_utils.py', 'recommenders/models/lightfm/__init__.py', 'recommenders/models/lightfm/lightfm_utils.py', 'recommenders/models/lightgbm/__init__.py', 'recommenders/models/lightgbm/lightgbm_utils.py', 'recommenders/models/ncf/__init__.py', 'recommenders/models/ncf/dataset.py', 'recommenders/models/ncf/ncf_singlenode.py', 'recommenders/models/newsrec/__init__.py', 'recommenders/models/newsrec/io/__init__.py', 'recommenders/models/newsrec/io/mind_all_iterator.py', 'recommenders/models/newsrec/io/mind_iterator.py', 'recommenders/models/newsrec/models/__init__.py', 'recommenders/models/newsrec/models/base_model.py', 'recommenders/models/newsrec/models/layers.py', 'recommenders/models/newsrec/models/lstur.py', 'recommenders/models/newsrec/models/naml.py', 'recommenders/models/newsrec/models/npa.py', 'recommenders/models/newsrec/models/nrms.py', 'recommenders/models/newsrec/newsrec_utils.py', 'recommenders/models/rbm/__init__.py', 'recommenders/models/rbm/rbm.py', 'recommenders/models/rlrmc/RLRMCalgorithm.py', 'recommenders/models/rlrmc/RLRMCdataset.py', 'recommenders/models/rlrmc/__init__.py', 'recommenders/models/rlrmc/conjugate_gradient_ms.py', 'recommenders/models/sar/__init__.py', 'recommenders/models/sar/sar_singlenode.py', 'recommenders/models/sasrec/__init__.py', 'recommenders/models/sasrec/model.py', 'recommenders/models/sasrec/sampler.py', 'recommenders/models/sasrec/ssept.py', 'recommenders/models/sasrec/util.py', 'recommenders/models/surprise/__init__.py', 'recommenders/models/surprise/surprise_utils.py', 'recommenders/models/tfidf/__init__.py', 'recommenders/models/tfidf/tfidf_utils.py', 'recommenders/models/vae/__init__.py', 'recommenders/models/vae/multinomial_vae.py', 'recommenders/models/vae/standard_vae.py', 'recommenders/models/vowpal_wabbit/__init__.py', 'recommenders/models/vowpal_wabbit/vw.py', 'recommenders/models/wide_deep/__init__.py', 'recommenders/models/wide_deep/wide_deep_utils.py', 'recommenders/tuning/__init__.py', 'recommenders/tuning/nni/__init__.py', 'recommenders/tuning/nni/ncf_training.py', 'recommenders/tuning/nni/ncf_utils.py', 'recommenders/tuning/nni/nni_utils.py', 'recommenders/tuning/nni/svd_training.py', 'recommenders/tuning/parameter_sweep.py', 'recommenders/utils/__init__.py', 'recommenders/utils/constants.py', 'recommenders/utils/general_utils.py', 'recommenders/utils/gpu_utils.py', 'recommenders/utils/k8s_utils.py', 'recommenders/utils/notebook_memory_management.py', 'recommenders/utils/notebook_utils.py', 'recommenders/utils/plot.py', 'recommenders/utils/python_utils.py', 'recommenders/utils/spark_utils.py', 'recommenders/utils/tf_utils.py', 'recommenders/utils/timer.py', 'scenarios/README.md', 'scenarios/ads/README.md', 'scenarios/food_and_restaurants/README.md', 'scenarios/gaming/README.md', 'scenarios/news/README.md', 'scenarios/retail/README.md', 'scenarios/travel/README.md', 'setup.py', 'tests/README.md', 'tests/__init__.py', 'tests/ci/README.md', 'tests/ci/__init__.py', 'tests/ci/azureml_tests/__init__.py', 'tests/ci/azureml_tests/run_groupwise_pytest.py', 'tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py', 'tests/ci/azureml_tests/test_groups.py', 'tests/conftest.py', 'tests/data_validation/__init__.py', 'tests/data_validation/examples/__init__.py', 'tests/data_validation/examples/test_mind.py', 'tests/data_validation/examples/test_wikidata.py', 'tests/data_validation/recommenders/__init__.py', 'tests/data_validation/recommenders/datasets/__init__.py', 'tests/data_validation/recommenders/datasets/test_covid_utils.py', 'tests/data_validation/recommenders/datasets/test_criteo.py', 'tests/data_validation/recommenders/datasets/test_mind.py', 'tests/data_validation/recommenders/datasets/test_movielens.py', 'tests/data_validation/recommenders/datasets/test_wikidata.py', 'tests/functional/__init__.py', 'tests/functional/examples/__init__.py', 'tests/functional/examples/test_notebooks_gpu.py', 'tests/functional/examples/test_notebooks_pyspark.py', 'tests/functional/examples/test_notebooks_python.py', 'tests/integration/__init__.py', 'tests/integration/recommenders/__init__.py', 'tests/integration/recommenders/utils/__init__.py', 'tests/integration/recommenders/utils/test_k8s_utils.py', 'tests/performance/__init__.py', 'tests/performance/recommenders/__init__.py', 'tests/performance/recommenders/evaluation/__init__.py', 'tests/performance/recommenders/evaluation/test_python_evaluation_time_performance.py', 'tests/regression/__init__.py', 'tests/regression/test_compatibility_tf.py', 'tests/responsible_ai/__init__.py', 'tests/responsible_ai/recommenders/__init__.py', 'tests/responsible_ai/recommenders/datasets/__init__.py', 'tests/responsible_ai/recommenders/datasets/test_criteo_privacy.py', 'tests/responsible_ai/recommenders/datasets/test_movielens_privacy.py', 'tests/security/__init__.py', 'tests/security/test_dependency_security.py', 'tests/smoke/__init__.py', 'tests/smoke/examples/__init__.py', 'tests/smoke/examples/test_notebooks_gpu.py', 'tests/smoke/examples/test_notebooks_pyspark.py', 'tests/smoke/examples/test_notebooks_python.py', 'tests/smoke/recommenders/__init__.py', 'tests/smoke/recommenders/recommender/__init__.py', 'tests/smoke/recommenders/recommender/test_deeprec_model.py', 'tests/smoke/recommenders/recommender/test_deeprec_utils.py', 'tests/smoke/recommenders/recommender/test_newsrec_model.py', 'tests/smoke/recommenders/recommender/test_newsrec_utils.py', 'tests/unit/__init__.py', 'tests/unit/examples/__init__.py', 'tests/unit/examples/test_notebooks_gpu.py', 'tests/unit/examples/test_notebooks_pyspark.py', 'tests/unit/examples/test_notebooks_python.py', 'tests/unit/recommenders/__init__.py', 'tests/unit/recommenders/datasets/__init__.py', 'tests/unit/recommenders/datasets/test_download_utils.py', 'tests/unit/recommenders/datasets/test_pandas_df_utils.py', 'tests/unit/recommenders/datasets/test_python_splitter.py', 'tests/unit/recommenders/datasets/test_spark_splitter.py', 'tests/unit/recommenders/datasets/test_sparse.py', 'tests/unit/recommenders/evaluation/__init__.py', 'tests/unit/recommenders/evaluation/conftest.py', 'tests/unit/recommenders/evaluation/test_python_evaluation.py', 'tests/unit/recommenders/evaluation/test_spark_evaluation.py', 'tests/unit/recommenders/models/__init__.py', 'tests/unit/recommenders/models/test_cornac_utils.py', 'tests/unit/recommenders/models/test_deeprec_model.py', 'tests/unit/recommenders/models/test_deeprec_utils.py', 'tests/unit/recommenders/models/test_geoimc.py', 'tests/unit/recommenders/models/test_lightfm_utils.py', 'tests/unit/recommenders/models/test_ncf_dataset.py', 'tests/unit/recommenders/models/test_ncf_singlenode.py', 'tests/unit/recommenders/models/test_newsrec_model.py', 'tests/unit/recommenders/models/test_newsrec_utils.py', 'tests/unit/recommenders/models/test_rbm.py', 'tests/unit/recommenders/models/test_sar_singlenode.py', 'tests/unit/recommenders/models/test_sasrec_model.py', 'tests/unit/recommenders/models/test_surprise_utils.py', 'tests/unit/recommenders/models/test_tfidf_utils.py', 'tests/unit/recommenders/models/test_vowpal_wabbit.py', 'tests/unit/recommenders/models/test_wide_deep_utils.py', 'tests/unit/recommenders/tuning/__init__.py', 'tests/unit/recommenders/tuning/test_ncf_utils.py', 'tests/unit/recommenders/tuning/test_nni_utils.py', 'tests/unit/recommenders/tuning/test_sweep.py', 'tests/unit/recommenders/utils/__init__.py', 'tests/unit/recommenders/utils/programmatic_notebook_execution.ipynb', 'tests/unit/recommenders/utils/test_general_utils.py', 'tests/unit/recommenders/utils/test_gpu_utils.py', 'tests/unit/recommenders/utils/test_notebook_utils.ipynb', 'tests/unit/recommenders/utils/test_notebook_utils.py', 'tests/unit/recommenders/utils/test_plot.py', 'tests/unit/recommenders/utils/test_python_utils.py', 'tests/unit/recommenders/utils/test_tf_utils.py', 'tests/unit/recommenders/utils/test_timer.py', 'tools/__init__.py', 'tools/databricks_install.py', 'tools/docker/Dockerfile', 'tools/docker/README.md'], 'assistantNextSteps': '1. Thoroughly analyze the repository structure and try to make some assumptions on the content of each file.2. Request contents of no more than 20 files. Order them by relevance descending. ', 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here is the content of the repository:\n",
      "{'branchName': 'main', 'files': [{'path': '.github/.codecov.yml', 'content': '# This file controls how codecov submit comments in the PR about code coverage.\\n# For more details, please see: \\n# https://docs.codecov.com/docs/pull-request-comments#section-behavior\\ncomment:\\n  behavior: default\\n\\nflags:\\n  nightly:\\n    joined: false'}], 'assistantNextSteps': '1. Analyze if the answer to the user question is contained in the returned files. 2. If yes, print the response to the user. If not, try to request the contents of another files.', 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here are the branches of the repository:\n",
      "{'branches': [{'name': '42-external-data-storage', 'headSha': 'a2643d0a9cee45d2475bb11ecb558de95fd5b061'}, {'name': 'chatbot', 'headSha': '4557e5fff1c64f420236c729c7149068562ac5f8'}, {'name': 'main', 'headSha': '87dcdbf196b78cf208b80a79973a9d69d763dee6'}, {'name': 'mlops', 'headSha': 'a194bec38218b170253532e9ca76f5b770f27937'}], 'assistantNextSteps': \"1. Respond with the list of branches. If not specified by user, render them as the list, where you'll display the branch name and the SHA of last commit. 2. Say to user that he can request the commit details for the last commit of each branch.\", 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here is the commit history of the repository:\n",
      "{'filePath': '.devcontainer/devcontainer.json', 'commits': [{'commitUrl': 'https://github.com/recommenders-team/recommenders/commit/846d214476bfb1f4e6898503bebb6a33a14db410', 'message': 'Adding codespace deployment (#1521)\\n\\n* adding codespace configuration\\r\\n\\r\\n* adding codespace configuration and dockerfile\\r\\n\\r\\n* fix java installation in codespace docker\\r\\n\\r\\n* adding installation for  package option\\r\\n\\r\\n* updating packages installed\\r\\n\\r\\n* updating ipykernel version and port forwarded for codespace\\r\\n\\r\\n* updating pip install and path\\r\\n\\r\\n* reverting postcreatecommand changes\\r\\n\\r\\n* using root for codespace\\r\\n\\r\\n* updating jupyter notebook setup and trying non-root user\\r\\n\\r\\n* fixes for using non-root user\\r\\n\\r\\n* allowing editable install into user by disabling pep517 for pip\\r\\n\\r\\n* allow user editable pip installs with user flag\\r\\n\\r\\n* removing duplicate env\\r\\n\\r\\n* adding port 4040 for spark monitoring\\r\\n\\r\\n* removing 4040 port fwd', 'commitDate': '2021-10-08T16:52:51', 'author': 'gramhagen'}], 'count': 1, 'assistantNextSteps': \"1. Print that you've successfully retrieved 1 commits from the file history. 2. Print the response to the user. 3. If you decide to print not all commits that were returned to you, notify user about that and ask if he wants to see others.  4. Notify user that you've retrieved all commits from the file history.\", 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here is the Code search result:\n",
      "{'branchName': 'main', 'searchResults': [{'path': 'recommenders/models/newsrec/models/npa.py', 'matches': ['    \"\"\"NPA model(Neural News Recommendation with Attentive Multi-View Learning)\\n\\n    Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang and Xing Xie:\\n    NPA: Neural News Recommendation with Personalized Attention, KDD 2019, ADS track.\\n\\n    Attributes:\\n        word2vec_embedding (numpy.ndarray): Pretrained word embedding matrix.\\n']}, {'path': 'recommenders/models/newsrec/models/nrms.py', 'matches': ['\\n\\nclass NRMSModel(BaseModel):\\n    \"\"\"NRMS model(Neural News Recommendation with Multi-Head Self-Attention)\\n\\n    Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang,and Xing Xie, \"Neural News\\n    Recommendation with Multi-Head Self-Attention\" in Proceedings of the 2019 Conference\\n']}, {'path': 'README.md', 'matches': ['| Multinomial VAE | Collaborative Filtering | Generative model for predicting user/item interactions. It works in the CPU/GPU environment. | [Deep dive](examples/02_model_collaborative_filtering/multi_vae_deep_dive.ipynb) |\\n| Neural Recommendation with Long- and Short-term User Representations (LSTUR)<sup>*</sup> | Content-Based Filtering | Neural recommendation algorithm for recommending news articles with long- and short-term user interest modeling. It works in the CPU/GPU environment. | [Quick start](examples/00_quick_start/lstur_MIND.ipynb) |\\n| Neural Recommendation with Attentive Multi-View Learning (NAML)<sup>*</sup> | Content-Based Filtering | Neural recommendation algorithm for recommending news articles with attentive multi-view learning. It works in the CPU/GPU environment. | [Quick start](examples/00_quick_start/naml_MIND.ipynb) |\\n', '| Neural Collaborative Filtering (NCF) | Collaborative Filtering | Deep learning algorithm with enhanced performance for user/item implicit feedback. It works in the CPU/GPU environment.| [Quick start](examples/00_quick_start/ncf_movielens.ipynb) / [Deep dive](examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb) |\\n| Neural Recommendation with Personalized Attention (NPA)<sup>*</sup> | Content-Based Filtering | Neural recommendation algorithm for recommending news articles with personalized attention network. It works in the CPU/GPU environment. | [Quick start](examples/00_quick_start/npa_MIND.ipynb) |\\n| Neural Recommendation with Multi-Head Self-Attention (NRMS)<sup>*</sup> | Content-Based Filtering | Neural recommendation algorithm for recommending news articles with multi-head self-attention. It works in the CPU/GPU environment. | [Quick start](examples/00_quick_start/nrms_MIND.ipynb) |\\n']}, {'path': 'examples/00_quick_start/npa_MIND.ipynb', 'matches': ['            \"cell_type\": \"markdown\",\\n            \"metadata\": {},\\n            \"source\": [\\n                \"# NPA: Neural News Recommendation with Personalized Attention\\\\n\",\\n                \"NPA \\\\\\\\[1\\\\\\\\] is a news recommendation model with personalized attention. The core of NPA is a news representation model and a user representation model. In the news representation model we use a CNN network to learn hidden representations of news articles based on their titles. In the user representation model we learn the representations of users based on the representations of their clicked news articles. In addition, a word-level and a news-level personalized attention are used to capture different informativeness for different users.\\\\n\",\\n                \"\\\\n\",\\n                \"## Properties of NPA:\\\\n\",\\n']}, {'path': 'examples/00_quick_start/naml_MIND.ipynb', 'matches': ['            \"source\": [\\n                \"# NAML: Neural News Recommendation with Attentive Multi-View Learning\\\\n\",\\n                \"NAML \\\\\\\\[1\\\\\\\\] is a multi-view news recommendation approach. The core of NAML is a news encoder and a user encoder. The newsencoder is composed of a title encoder, a body encoder, a vert encoder and a subvert encoder. The CNN-based title encoder and body encoder learn title and body representations by capturing words semantic information. After getting news title, body, vert and subvert representations, an attention network is used to aggregate those vectors. In the user encoder, we learn representations of users from their browsed news. Besides, we apply additive attention to learn more informative news and user representations by selecting important words and news.\\\\n\",\\n', '                \"## Properties of NAML:\\\\n\",\\n                \"- NAML is a multi-view neural news recommendation approach.\\\\n\",\\n                \"- It uses news title, news body, news vert and news subvert to get news repersentations. And it uses user historical behaviors to learn user representations.\\\\n\",\\n']}, {'path': 'examples/00_quick_start/nrms_MIND.ipynb', 'matches': ['            \"source\": [\\n                \"# NRMS: Neural News Recommendation with Multi-Head Self-Attention\\\\n\",\\n                \"NRMS \\\\\\\\[1\\\\\\\\] is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive\\\\n\",\\n', '                \"## Reference\\\\n\",\\n                \"\\\\\\\\[1\\\\\\\\] Wu et al. \\\\\"Neural News Recommendation with Multi-Head Self-Attention.\\\\\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<br>\\\\n\",\\n                \"\\\\\\\\[2\\\\\\\\] Wu, Fangzhao, et al. \\\\\"MIND: A Large-scale Dataset for News Recommendation\\\\\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\\\\n\",\\n']}, {'path': 'examples/00_quick_start/lstur_MIND.ipynb', 'matches': ['            \"cell_type\": \"markdown\",\\n            \"metadata\": {},\\n            \"source\": [\\n                \"# LSTUR: Neural News Recommendation with Long- and Short-term User Representations\\\\n\",\\n                \"LSTUR \\\\\\\\[1\\\\\\\\] is a news recommendation approach capturing users\\' both long-term preferences and short-term interests. The core of LSTUR is a news encoder and a user encoder.  In the news encoder, we learn representations of news from their titles. In user encoder, we propose to learn long-term\\\\n\",\\n                \"user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine\\\\n\",\\n                \"long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both\\\\n\",\\n']}, {'path': 'examples/00_quick_start/dkn_MIND.ipynb', 'matches': ['            \"source\": [\\n                \"# DKN : Deep Knowledge-Aware Network for News Recommendation\\\\n\",\\n                \"\\\\n\",\\n                \"DKN \\\\\\\\[1\\\\\\\\] is a deep learning model which incorporates information from knowledge graph for better news recommendation. Specifically, DKN uses TransX \\\\\\\\[2\\\\\\\\] method for knowledge graph representation learning, then applies a CNN framework, named KCNN, to combine entity embedding with word embedding and generate a final embedding vector for a news article. CTR prediction is made via an attention-based neural scorer. \\\\n\",\\n                \"\\\\n\",\\n                \"## Properties of DKN:\\\\n\",\\n                \"\\\\n\",\\n']}, {'path': 'recommenders/models/newsrec/models/naml.py', 'matches': ['    \"\"\"NAML model(Neural News Recommendation with Attentive Multi-View Learning)\\n\\n    Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang and Xing Xie,\\n    Neural News Recommendation with Attentive Multi-View Learning, IJCAI 2019\\n\\n    Attributes:\\n        word2vec_embedding (numpy.ndarray): Pretrained word embedding matrix.\\n']}, {'path': 'recommenders/models/newsrec/models/lstur.py', 'matches': ['    \"\"\"LSTUR model(Neural News Recommendation with Multi-Head Self-Attention)\\n\\n    Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie:\\n    Neural News Recommendation with Long- and Short-term User Representations, ACL 2019\\n\\n    Attributes:\\n        word2vec_embedding (numpy.ndarray): Pretrained word embedding matrix.\\n']}, {'path': 'recommenders/README.md', 'matches': ['* LightGBM\\n* NCF\\n* NewsRec\\n  * Neural Recommendation with Long- and Short-term User Representations (LSTUR)\\n  * Neural Recommendation with Attentive Multi-View Learning (NAML)\\n  * Neural Recommendation with Personalized Attention (NPA)\\n  * Neural Recommendation with Multi-Head Self-Attention (NRMS)\\n']}, {'path': 'examples/02_model_content_based_filtering/dkn_deep_dive.ipynb', 'matches': ['            \"source\": [\\n                \"# DKN : Deep Knowledge-Aware Network for News Recommendation\\\\n\",\\n                \"\\\\n\",\\n                \"DKN \\\\\\\\[1\\\\\\\\] is a deep learning model which incorporates information from knowledge graph for better news recommendation. Specifically, DKN uses TransX \\\\\\\\[2\\\\\\\\] method for knowledge graph representation learning, then applies a CNN framework, named KCNN, to combine entity embedding with word embedding and generate a final embedding vector for a news article. CTR prediction is made via an attention-based neural scorer. \\\\n\",\\n                \"\\\\n\",\\n                \"## Properties of DKN:\\\\n\",\\n                \"\\\\n\",\\n']}, {'path': 'examples/00_quick_start/README.md', 'matches': ['[4] _Restricted Boltzmann Machines for Collaborative Filtering_, Ruslan Salakhutdinov, Andriy Mnih and Geoffrey Hinton. ICML 2007.<br>\\n[5] _Wide & Deep Learning for Recommender Systems_, Heng-Tze Cheng et al., arXiv:1606.07792 2016. <br>\\n[6] _A unified framework for structured low-rank matrix learning_, Pratik Jawanpuria and Bamdev Mishra, In International Conference on Machine Learning, 2018. <br>\\n[7] _NAML: Neural News Recommendation with Attentive Multi-View Learning_, Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang and Xing Xie. IJCAI 2019.<br>\\n[8] _NRMS: Neural News Recommendation with Multi-Head Self-Attention_, Chuhan Wu, Fangzhao Wu, Suyu Ge, Tao Qi, Yongfeng Huang, Xing Xie. in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).<br>\\n[9] _LSTUR: Neural News Recommendation with Long- and Short-term User Representations_, Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie. ACL 2019.<br>\\n[10] _NPA: Neural News Recommendation with Personalized Attention_, Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang and Xing Xie. KDD 2019, ADS track.<br>\\n']}, {'path': 'examples/07_tutorials/KDD2020-tutorial/step3_run_dkn.ipynb', 'matches': ['            \"metadata\": {},\\n            \"source\": [\\n                \"# DKN : Deep Knowledge-Aware Network for News Recommendation\\\\n\",\\n                \"DKN \\\\\\\\[1\\\\\\\\] is a deep learning model which incorporates information from knowledge graph for better news recommendation. Specifically, DKN uses TransX \\\\\\\\[2\\\\\\\\] method for knowledge graph representaion learning, then applies a CNN framework, named KCNN, to combine entity embedding with word embedding and generate a final embedding vector for a news article. CTR prediction is made via an attention-based neural scorer. \\\\n\",\\n                \"<img src=\\\\\"https://recodatasets.z20.web.core.windows.net/kdd2020/images%2FDKN-introduction-pic.JPG\\\\\" width=\\\\\"600\\\\\">\\\\n\",\\n                \"\\\\n\",\\n                \"## Properties of DKN:\\\\n\",\\n']}, {'path': 'examples/07_tutorials/KDD2020-tutorial/step2_pretraining-embeddings.ipynb', 'matches': ['                \"## Reference\\\\n\",\\n                \"\\\\\\\\[1\\\\\\\\] Wang, Hongwei, et al. \\\\\"DKN: Deep Knowledge-Aware Network for News Recommendation.\\\\\" Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2018.<br>\\\\n\",\\n                \"\\\\\\\\[2\\\\\\\\] Knowledge Graph Embeddings including TransE, TransH, TransR and PTransE. https://github.com/thunlp/KB2E <br>\\\\n\",\\n', '                \"\\\\\\\\[3\\\\\\\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/ <br>\\\\n\",\\n                \"\\\\\\\\[4\\\\\\\\] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed representations of words and phrases and their compositionality. In Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2 (NIPS’13). Curran Associates Inc., Red Hook, NY, USA, 3111–3119. <br>\\\\n\",\\n                \"\\\\\\\\[5\\\\\\\\] Gensim  Word2vec embeddings : https://radimrehurek.com/gensim/models/word2vec.html <br>\"\\n']}], 'assistantNextSteps': '1. Analyze the response and returned matches.2. If they answer users question, print the response. If not, try to either search with different keywords, or try to get the full file contents.', 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here is the Commits search result:\n",
      "{'commits': [{'url': 'https://github.com/recommenders-team/recommenders/commit/d090846697b7837914e10f353b5bc80dff3f5a0f', 'message': 'Documentation working\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Documentation working\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/69a485c50f950adcf4da7e8189725224f5850a57', 'message': 'Merge pull request #2051 from recommenders-team/miguel/jupyter_book\\n\\nNew documentation with Jupyter book', 'matches': ['Merge pull request #2051 from recommenders-team/miguel/jupyter_book\\n\\nNew documentation with Jupyter book']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/310370b2a0fd3366bce264b9b007ad6d6af330e0', 'message': 'Merge pull request #2057 from recommenders-team/staging\\n\\nStaging to main: New documentation with Jupyter Book', 'matches': ['Merge pull request #2057 from recommenders-team/staging\\n\\nStaging to main: New documentation with Jupyter Book']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/32ee9d8a942a282fa9d3db95d8cee69d32a24556', 'message': 'Change the way we compile the documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Change the way we compile the documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/769900801872e9f381aebeaff7ab6536f5c7614c', 'message': 'Update documentation badge\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Update documentation badge\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/9263c7d3914b3790eab182d5ac91a9181c84f825', 'message': 'actions to automatically update documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['actions to automatically update documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/006a33d8c78b4e806d590fd1d366d60e73d194e2', 'message': 'actions to automatically update documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['actions to automatically update documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/9474dff874773430384606710fe91a27c7ce4ff1', 'message': 'Creating documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Creating documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/b3217f813a0e0eb8d887ac38ba919757ae7966a4', 'message': 'actions to automatically update documentation :bug:\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['actions to automatically update documentation :bug:\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/5a221df288a6bf1d2a5bbe7655f3abd967f9365a', 'message': 'actions to automatically update documentation :bug:\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['actions to automatically update documentation :bug:\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/b887e439f743a5a02f7719cf7888434ea884a3e8', 'message': 'Automatic build of documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Automatic build of documentation\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/1d308a4e0a538b3fa2dc0dfb94e9c46c2f385266', 'message': 'Merge pull request #2055 from recommenders-team/staging\\n\\nStaging to main: Documentation update, algorithm classification update and fix error in MIND', 'matches': ['Merge pull request #2055 from recommenders-team/staging\\n\\nStaging to main: Documentation update, algorithm classification update and fix error in MIND']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/42cd1525b7a59fca9bf39b587354b43b38f6a4da', 'message': 'Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/23fa87c4d275e949f93cbc8cdccc60b9e8512154', 'message': 'Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/20720f59c99d9967f83162368fa988d7e6fcc2a0', 'message': 'Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Automatic build of documentation deps\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/87225505814cbaba0de3e4d0b825268227817aa4', 'message': 'Automatic build of documentation dev\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>', 'matches': ['Automatic build of documentation dev\\n\\nSigned-off-by: miguelgfierro <miguelgfierro@users.noreply.github.com>']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/787ae309ec78a9b2b1f58931931cb117affc4ea9', 'message': 'Merge pull request #1940 from microsoft/staging\\n\\nStaging to main: fix tests and update documentation', 'matches': ['Merge pull request #1940 from microsoft/staging\\n\\nStaging to main: fix tests and update documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/8ee1ed3ac0db04321b064edb6f10d6af0bb318fd', 'message': 'Merge pull request #1908 from microsoft/staging\\n\\nStaging to main: improvements in testing pipeline and documentation', 'matches': ['Merge pull request #1908 from microsoft/staging\\n\\nStaging to main: improvements in testing pipeline and documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/53c01881843b256ab33bffffa91bdf6e363e6f6a', 'message': 'Merge pull request #1729 from microsoft/pradjoshi/azureml_doc\\n\\nUpdate AzureML test documentation', 'matches': ['Merge pull request #1729 from microsoft/pradjoshi/azureml_doc\\n\\nUpdate AzureML test documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/dbf7ed08d36b4c77e5455c2c3ba165d6308aeaaf', 'message': 'update loss function documentation', 'matches': ['update loss function documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/772185788ec037a9e53a2e498586bcaecb224798', 'message': 'Merge pull request #1690 from microsoft/bug/doc\\n\\nFixed readthedocs bug and added SASRec and SSEPT documentation', 'matches': ['Merge pull request #1690 from microsoft/bug/doc\\n\\nFixed readthedocs bug and added SASRec and SSEPT documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/35178cef961d617949bd1878c037c246d37b3bfc', 'message': 'Change Java version in documentation', 'matches': ['Change Java version in documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/1e652115bc8e76b3c5ec1c7c33e5bd935376ff8f', 'message': 'Update dev documentation', 'matches': ['Update dev documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/6e09f4e4275158873d47f567bc9dce030f697479', 'message': 'danb27/sar_single_node_improvements: allow for getting most frequent users, similar users, and fix self.item_frequencies to actually use frequencies as stated in documentation', 'matches': ['danb27/sar_single_node_improvements: allow for getting most frequent users, similar users, and fix self.item_frequencies to actually use frequencies as stated in documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/07b9399bd7c90e2e27f953dbf7960d11578a3b0d', 'message': 'Update test-running documentation', 'matches': ['Update test-running documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/99379a65b34b1e2e42ce293244eb9914fe71f672', 'message': 'Merge pull request #859 from microsoft/documentation\\n\\nDocumentation of Recommenders', 'matches': ['Merge pull request #859 from microsoft/documentation\\n\\nDocumentation of Recommenders']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/6594a96c58936f7ac76dc324dcd9a79ac59e99d6', 'message': 'Merge pull request #859 from microsoft/documentation\\n\\nDocumentation of Recommenders', 'matches': ['Merge pull request #859 from microsoft/documentation\\n\\nDocumentation of Recommenders']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/dc7de0d875491e7d89c4b106a231c543b635606d', 'message': 'rbm documentation', 'matches': ['rbm documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/107e44fed01b2cebabb49d37ab37cbc4f09d577f', 'message': 'rbm documentation', 'matches': ['rbm documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/7e707419b8a340ca96c8c06d756d7966d7e0e25b', 'message': 'review documentation', 'matches': ['review documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/f649868e087eef86dc63c1d909d42ca7198b59b1', 'message': 'review documentation', 'matches': ['review documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/3fe9507832a6b293e9c0c92dc0f1e9a8640ed5a3', 'message': 'fixed documentation', 'matches': ['fixed documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/94e81cd357a18b7cc1e0d180284b7c047e5228ef', 'message': 'fixed documentation', 'matches': ['fixed documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/b93d8fa391a4ffaa04f8a88ef99595a7ac73c257', 'message': 'fixed documentation', 'matches': ['fixed documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/bd14234cb7eb066ee4ea0ecedc08e13ab99cbc06', 'message': 'fixed documentation', 'matches': ['fixed documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/015ea427a04c495db6ec2f5e99a71024749bc0c1', 'message': 'review documentation :boom:', 'matches': ['review documentation :boom:']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/31760f9e07ceb611519f087cfbaf86a7ff2250c0', 'message': 'review documentation :boom:', 'matches': ['review documentation :boom:']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/95aa96228adb41195f56f9f658777e33126a5ace', 'message': 'change in the documentation', 'matches': ['change in the documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/1af5e92508f5dc7b6aa1d8294f5a0937f4c28cbd', 'message': 'change in the documentation', 'matches': ['change in the documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/2ba26b348db7f60e720882cebe0ccc290943589e', 'message': 'fixed documentation for RBM', 'matches': ['fixed documentation for RBM']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/cb2eb8d71b76ec130ae6cf48a9b1b9c000db38e0', 'message': 'fixed documentation for RBM', 'matches': ['fixed documentation for RBM']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/5174df94ff097c3d6e4bf755731486f7f2c788d0', 'message': 'Merge pull request #80 from Microsoft/nikhil/documentation\\n\\nnotebook documentation in single node SAR and educational SAR notebooks\\r\\n\\r\\nfixes #57', 'matches': ['Merge pull request #80 from Microsoft/nikhil/documentation\\n\\nnotebook documentation in single node SAR and educational SAR notebooks\\r\\n\\r\\nfixes #57']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/23b4dc156fbb85add0849a4ec8c2793ef7fd89d7', 'message': 'Merge pull request #80 from Microsoft/nikhil/documentation\\n\\nnotebook documentation in single node SAR and educational SAR notebooks\\r\\n\\r\\nfixes #57', 'matches': ['Merge pull request #80 from Microsoft/nikhil/documentation\\n\\nnotebook documentation in single node SAR and educational SAR notebooks\\r\\n\\r\\nfixes #57']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/0f55c7f3ef6bfd01a3629e7f99f3dde2b25c0d23', 'message': 'updated documentation', 'matches': ['updated documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/248f91bb5ececb3e09e93315c7799ac97405b26f', 'message': 'updated documentation', 'matches': ['updated documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/aee5f37ae56b44da61e3b7e4b68444bb87a53f5b', 'message': 'Add sphinx documentation for wikidata', 'matches': ['Add sphinx documentation for wikidata']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/65855669e21116218bf9ea96c1e43a370954ba71', 'message': 'Add sphinx documentation for wikidata', 'matches': ['Add sphinx documentation for wikidata']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/1a7ae02addc783b7707aebe7870ef0d07324bba2', 'message': \"Merge branch 'staging' into documentation\", 'matches': [\"Merge branch 'staging' into documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/aa660197d14d25cea9f4f0b3145c3b602af7a6b9', 'message': \"Merge branch 'staging' into documentation\", 'matches': [\"Merge branch 'staging' into documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/510c88b3167b3fb5ed6415f4d472fdf87cfd201f', 'message': \"Merge branch 'staging' into documentation\", 'matches': [\"Merge branch 'staging' into documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/61664516ae108a71d8e083c80b89eb35590587aa', 'message': \"Merge branch 'staging' into documentation\", 'matches': [\"Merge branch 'staging' into documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/848168cb4953692d835de47d73940a70a034a759', 'message': 'sar documentation', 'matches': ['sar documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/eff7aba831cb8bdcd2b4a5dbed8f6c4def67f076', 'message': 'sar documentation', 'matches': ['sar documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/f57be9d20180cfd6fcf6b2ede596b2adeefca4e2', 'message': 'fixing documentation :bug: related to #817', 'matches': ['fixing documentation :bug: related to #817']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/8660a1949990c9a8ea599fb96ebd7877669efc00', 'message': 'fixing documentation :bug: related to #817', 'matches': ['fixing documentation :bug: related to #817']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/81acd1cd9a788268ccbf82e86819ba5a5ecc24eb', 'message': 'added some documentation', 'matches': ['added some documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/7c0472dae54efc3cea16a2674cdb4dff2d00b43b', 'message': 'added some documentation', 'matches': ['added some documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/6a91ccbc829c8bbd07d0fabe492f791f32b50fad', 'message': 'improved documentation; reverted unit test refactoring', 'matches': ['improved documentation; reverted unit test refactoring']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/c6a23a0a26bb1a7c29b516c38d8795857d84e8c7', 'message': 'improved documentation; reverted unit test refactoring', 'matches': ['improved documentation; reverted unit test refactoring']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/7333b1852b7f4e24a5a1d5622a2b026143f3414f', 'message': \"Merge branch 'staging' into nikhil/documentation\", 'matches': [\"Merge branch 'staging' into nikhil/documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/2e904303b10c9bb9fc55a67da4ffb46b0448c710', 'message': \"Merge branch 'staging' into nikhil/documentation\", 'matches': [\"Merge branch 'staging' into nikhil/documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/cedd2dff450481617214e547f535fab50908329a', 'message': \"Merge branch 'staging' into nikhil/documentation\", 'matches': [\"Merge branch 'staging' into nikhil/documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/ee29c9e0a7d2602c8f55851fb11de597b89d503b', 'message': \"Merge branch 'staging' into nikhil/documentation\", 'matches': [\"Merge branch 'staging' into nikhil/documentation\"]}, {'url': 'https://github.com/recommenders-team/recommenders/commit/fe8c389eab55be1c27731234dc0e045043583ea7', 'message': 'documentation, improved tests in wide and deep model and fix :bug: in tests', 'matches': ['documentation, improved tests in wide and deep model and fix :bug: in tests']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/287718bc97cd9b25b414352371917848f50345fc', 'message': 'documentation, improved tests in wide and deep model and fix :bug: in tests', 'matches': ['documentation, improved tests in wide and deep model and fix :bug: in tests']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/56b6451bf2ebf4dec9937ba68202dabe999887f9', 'message': 'Merge pull request #879 from microsoft/miguelgfierro-patch-1\\n\\nAdd sphinx documentation for wikidata', 'matches': ['Merge pull request #879 from microsoft/miguelgfierro-patch-1\\n\\nAdd sphinx documentation for wikidata']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/7339405996eaf04e1143c77b04c94e5f79e6a979', 'message': 'Merge pull request #879 from microsoft/miguelgfierro-patch-1\\n\\nAdd sphinx documentation for wikidata', 'matches': ['Merge pull request #879 from microsoft/miguelgfierro-patch-1\\n\\nAdd sphinx documentation for wikidata']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/1906408a4fb57f1349e63e75ae38fc87c6574e9f', 'message': 'Merge pull request #482 from Microsoft/doc/tests\\n\\nadded papermill documentation', 'matches': ['Merge pull request #482 from Microsoft/doc/tests\\n\\nadded papermill documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/b0a177e6feff4097c7b4aa7cf85b1adc904acb16', 'message': 'Merge pull request #482 from Microsoft/doc/tests\\n\\nadded papermill documentation', 'matches': ['Merge pull request #482 from Microsoft/doc/tests\\n\\nadded papermill documentation']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/71a38d422c00329f8f8226ea24ad6260b1b7b4e9', 'message': 'Merge pull request #867 from microsoft/staging\\n\\nStaging to master after documentation and other changes', 'matches': ['Merge pull request #867 from microsoft/staging\\n\\nStaging to master after documentation and other changes']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/67ebc0d740453b22c7e87e331a4ee57a790909f6', 'message': 'adding skips for mmlspark_lightgbm tests on windows, updating test documentation to track skips', 'matches': ['adding skips for mmlspark_lightgbm tests on windows, updating test documentation to track skips']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/75695d5d7ff88e7836e68e37bacd191117ba13d2', 'message': 'adding skips for mmlspark_lightgbm tests on windows, updating test documentation to track skips', 'matches': ['adding skips for mmlspark_lightgbm tests on windows, updating test documentation to track skips']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/4fef4f4594b66e30bbe8a784a45391aa4ea31218', 'message': 'fixed capitalization of pyspark\\n\\nPySpark documentation has it capitalized as \"PySpark\" rather than \"pySpark\".', 'matches': ['fixed capitalization of pyspark\\n\\nPySpark documentation has it capitalized as \"PySpark\" rather than \"pySpark\".']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/46520520ece0eadc1c3647998e8dfce93774fa0a', 'message': 'fixed capitalization of pyspark\\n\\nPySpark documentation has it capitalized as \"PySpark\" rather than \"pySpark\".', 'matches': ['fixed capitalization of pyspark\\n\\nPySpark documentation has it capitalized as \"PySpark\" rather than \"pySpark\".']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/65d2b600acb75832c0194282278b87642a63671f', 'message': 'Merge pull request #325 from Microsoft/sgraham/readme\\n\\nChanges to readme documentation throughout repo', 'matches': ['Merge pull request #325 from Microsoft/sgraham/readme\\n\\nChanges to readme documentation throughout repo']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/df94ca603445db0780959d7865aa2e3e1a456d28', 'message': 'Merge pull request #325 from Microsoft/sgraham/readme\\n\\nChanges to readme documentation throughout repo', 'matches': ['Merge pull request #325 from Microsoft/sgraham/readme\\n\\nChanges to readme documentation throughout repo']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/7d5070ef5a271b11ea8776a0c9472a23c3e98af8', 'message': 'Adding default environment yaml.\\n\\nThe jupyter tool \"jupyter-repo2docker\" expects an environment.yml file in the root of the repo directory. While there may be other configs that could be added, adding this file would also enable creating a base conda env with the default commands, without changing any of the existing documentation.', 'matches': ['Adding default environment yaml.\\n\\nThe jupyter tool \"jupyter-repo2docker\" expects an environment.yml file in the root of the repo directory. While there may be other configs that could be added, adding this file would also enable creating a base conda env with the default commands, without changing any of the existing documentation.']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/f69f0140614bc0bb2a4506fb59dbc6f19449335a', 'message': 'Docker Support (#718)\\n\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo', 'matches': ['Docker Support (#718)\\n\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/83e0d69093d8f40b4b55dd13d87a9b12141deac4', 'message': 'Docker Support (#718)\\n\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo', 'matches': ['Docker Support (#718)\\n\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo']}, {'url': 'https://github.com/recommenders-team/recommenders/commit/e8ee8aa63b80dc972fd901e841d84096f730f3ba', 'message': 'Staging to master (#882)\\n\\n* new file with wikidata functions\\r\\n\\r\\n* fix in json extraction\\r\\n\\r\\n* new notebook with wikidata use examples\\r\\n\\r\\n* retry request with lowercase in case of failure\\r\\n\\r\\n* WIP: example creating KG from movielens entities\\r\\n\\r\\n* introduced new step to retrieve first page title from a text query in wikipedia\\r\\n\\r\\n* updated movielens links extraction using wikidata\\r\\n\\r\\n* adapted docstrings for sphinx and removed parenthesis from output\\r\\n\\r\\n* added description and labels to nodes to graph preview\\r\\n\\r\\n* https://github.com/microsoft/recommenders/pull/778#discussion_r294565020 new format for queries\\r\\n\\r\\n* raising exceptions in requests and using get() to retrieve dict values\\r\\n\\r\\n* moved imports to first cell and movielens size as a parameter\\r\\n\\r\\n* output file name as paramenter\\r\\n\\r\\n* DATA: update sum check\\r\\n\\r\\n* adding unit test for sum to 1 issue\\r\\n\\r\\n* improved description and adapted to tests\\r\\n\\r\\n* improved Exception descriptions\\r\\n\\r\\n* integration tests\\r\\n\\r\\n* unit tests\\r\\n\\r\\n* added wikidata_KG to conftest\\r\\n\\r\\n* changed name notebook\\r\\n\\r\\n* *NOTE: Adding  shows the computation time of all tests.*\\r\\n\\r\\n* imports up\\r\\n\\r\\n* Update wikidata.py\\r\\n\\r\\n* changed default parameter of sample for tests\\r\\n\\r\\n* Add sphinx documentation for wikidata\\r\\n\\r\\n* modified parameter extraction for tests\\r\\n\\r\\n* added parameters tag to cell\\r\\n\\r\\n* changed default sampling to test parameters in test\\r\\n\\r\\n* notebook cleaned cells output\\r\\n\\r\\n* Docker Support (#718)\\r\\n\\r\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo', 'matches': ['Staging to master (#882)\\n\\n* new file with wikidata functions\\r\\n\\r\\n* fix in json extraction\\r\\n\\r\\n* new notebook with wikidata use examples\\r\\n\\r\\n* retry request with lowercase in case of failure\\r\\n\\r\\n* WIP: example creating KG from movielens entities\\r\\n\\r\\n* introduced new step to retrieve first page title from a text query in wikipedia\\r\\n\\r\\n* updated movielens links extraction using wikidata\\r\\n\\r\\n* adapted docstrings for sphinx and removed parenthesis from output\\r\\n\\r\\n* added description and labels to nodes to graph preview\\r\\n\\r\\n* https://github.com/microsoft/recommenders/pull/778#discussion_r294565020 new format for queries\\r\\n\\r\\n* raising exceptions in requests and using get() to retrieve dict values\\r\\n\\r\\n* moved imports to first cell and movielens size as a parameter\\r\\n\\r\\n* output file name as paramenter\\r\\n\\r\\n* DATA: update sum check\\r\\n\\r\\n* adding unit test for sum to 1 issue\\r\\n\\r\\n* improved description and adapted to tests\\r\\n\\r\\n* improved Exception descriptions\\r\\n\\r\\n* integration tests\\r\\n\\r\\n* unit tests\\r\\n\\r\\n* added wikidata_KG to conftest\\r\\n\\r\\n* changed name notebook\\r\\n\\r\\n* *NOTE: Adding  shows the computation time of all tests.*\\r\\n\\r\\n* imports up\\r\\n\\r\\n* Update wikidata.py\\r\\n\\r\\n* changed default parameter of sample for tests\\r\\n\\r\\n* Add sphinx documentation for wikidata\\r\\n\\r\\n* modified parameter extraction for tests\\r\\n\\r\\n* added parameters tag to cell\\r\\n\\r\\n* changed default sampling to test parameters in test\\r\\n\\r\\n* notebook cleaned cells output\\r\\n\\r\\n* Docker Support (#718)\\r\\n\\r\\n* DOCKER: add pyspark docker file\\r\\n\\r\\n* DOCKER: remove unused line\\r\\n\\r\\n* DOCKER: remove old file\\r\\n\\r\\n* DOCKER: add SETUP text\\r\\n\\r\\n* DOCKER: add azureml`\\r\\n\\r\\n* DOCKER: udpate dockerfile\\r\\n\\r\\n* DOCKER: use a branch of the repo\\r\\n\\r\\n* SETUP: update setup\\r\\n\\r\\n* DOCKER: update dockerfile\\r\\n\\r\\n* DOC: update setup\\r\\n\\r\\n* DOCKER: one that binds all\\r\\n\\r\\n* SETUP: update docker use\\r\\n\\r\\n* DOCKER: move to top level\\r\\n\\r\\n* SETUP: use a different base name\\r\\n\\r\\n* DOCKER: use the same keywords in the repo for environment arg\\r\\n\\r\\n* SETUP: update environment variable names\\r\\n\\r\\n* updating dockerfile to use multistage build and adding readme\\r\\n\\r\\n* adding full stage\\r\\n\\r\\n* fixing documentation\\r\\n\\r\\n* adding info for running full env\\r\\n\\r\\n* README: update notes for exporting environment on certain platform\\r\\n\\r\\n* README: updated with example on Windows\\r\\n\\r\\n* README: fix typo']}], 'totalCount': 80, 'assistantNextSteps': \"1. Print that you've successfully retrieved 80 most relevant commits. 2. Print the response to the user. Suggest user to refine his search if he is interested in other commits.\", 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here are the repositories found:\n",
      "{'repositories': [{'name': 'recommenders', 'url': 'https://github.com/recommenders-team/recommenders', 'description': 'Best Practices on Recommendation Systems'}, {'name': 'recommenders', 'url': 'https://github.com/tensorflow/recommenders', 'description': 'TensorFlow Recommenders is a library for building recommender system models using TensorFlow.'}, {'name': 'AI-RecommenderSystem', 'url': 'https://github.com/zhongqiangwu960812/AI-RecommenderSystem', 'description': '该仓库尝试整理推荐系统领域的一些经典算法模型'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/wangshusen/RecommenderSystem'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/DeepGraphLearning/RecommenderSystems'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/apachecn/RecommenderSystems', 'description': '推荐系统'}, {'name': 'RecommenderSystem-Paper', 'url': 'https://github.com/daicoolb/RecommenderSystem-Paper', 'description': 'This repository includes some papers that I have read or which I think may be very interesting.'}, {'name': 'recommenders-addons', 'url': 'https://github.com/tensorflow/recommenders-addons', 'description': 'Additional utils and helpers to extend TensorFlow when build recommendation systems, contributed and maintained by SIG Recommenders.'}, {'name': 'RecommenderSystem-DataSet', 'url': 'https://github.com/daicoolb/RecommenderSystem-DataSet', 'description': 'This repository contains some datasets that I have collected in Recommender Systems.'}, {'name': 'deep_recommenders', 'url': 'https://github.com/LongmaoTeamTf/deep_recommenders', 'description': 'Deep Recommenders'}, {'name': 'RecommenderSystems_PyData_2016', 'url': 'https://github.com/dvysardana/RecommenderSystems_PyData_2016'}, {'name': 'recommenders_engine_example_layout', 'url': 'https://github.com/microsoft/recommenders_engine_example_layout', 'description': 'An example cross-platform movie recommendation application built using Xamarin.Forms and Azure ML service'}, {'name': 'evaluating-recommenders', 'url': 'https://github.com/zygmuntz/evaluating-recommenders', 'description': 'Compute and plot NDCG for a recommender system'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/oreilly-japan/RecommenderSystems', 'description': '『推薦システム実践入門』のリポジトリ'}, {'name': 'matrix_factorization_recommenders', 'url': 'https://github.com/beckernick/matrix_factorization_recommenders', 'description': 'Low-Rank Matrix Factorization for Recommender Systems'}, {'name': 'deeplearning4recommendersystem', 'url': 'https://github.com/cheungdaven/deeplearning4recommendersystem', 'description': 'deep learning for recommender system'}, {'name': 'pydata_2016_talk_recommenders', 'url': 'https://github.com/manugarri/pydata_2016_talk_recommenders', 'description': 'PyData Madrid 2016 material for the talk: A Primer to recommendation Systems'}, {'name': 'session_based_recommenders', 'url': 'https://github.com/fastforwardlabs/session_based_recommenders', 'description': 'Official repo for FF19: Session-based Recommender Systems'}, {'name': 'HyperbolicRecommenders', 'url': 'https://github.com/evfro/HyperbolicRecommenders', 'description': 'Accompanying code for the paper Performance of Hyperbolic Geometry Models on Top-N Recommendation Tasks, accepted at ACM RecSys 2020.'}, {'name': 'RecommenderSystemsNotebooks', 'url': 'https://github.com/caiomiyashiro/RecommenderSystemsNotebooks', 'description': \"Set of notebooks analysing and discussing the ideas presented at Coursera's Recommender Systems course\"}, {'name': 'recommenderSystem', 'url': 'https://github.com/truedei/recommenderSystem', 'description': 'java实现的商品推荐系统（含爬取的数据，详细的说明书，等）'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/Yuziquan/RecommenderSystem', 'description': 'A network TV program recommendation system implemented by python is mainly based on the post-fusion of user collaborative filtering and content-based recommendation algorithms.'}, {'name': 'recommenders', 'url': 'https://github.com/eclipse-archived/recommenders', 'description': 'Code Recommenders project repository (recommenders)'}, {'name': 'RecommenderSystem-Paper', 'url': 'https://github.com/chenboability/RecommenderSystem-Paper', 'description': 'some papers about the recommender system'}, {'name': 'recommenderSystemBasedOnSpark', 'url': 'https://github.com/toughhou/recommenderSystemBasedOnSpark', 'description': '基于spark的推荐系统的实现（电影推荐系统）'}, {'name': 'Recommending-the-Recommenders', 'url': 'https://github.com/NalinDadhich/Recommending-the-Recommenders', 'description': 'Finding relevant source domain for a cross-domain recommendation system using Unified Content-based Collaborative Filtering (CCCFNet model)'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/mdh266/RecommenderSystems', 'description': 'Recommender Systems and Collaborative Filtering '}, {'name': 'Unsupervised-Learning-Recommenders-Reinforcement-Learning', 'url': 'https://github.com/rediar/Unsupervised-Learning-Recommenders-Reinforcement-Learning', 'description': 'My solutions for https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning'}, {'name': 'RecommenderSystems_R', 'url': 'https://github.com/sureshgorakala/RecommenderSystems_R', 'description': 'Scripts for recommender systems'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/zwtforest/RecommenderSystems', 'description': '程序以matlab语言编写，包括了Pearson相似度、UserCF、ItemCF、slope one算法、TopN推荐、MAE、RMSE、准确度、覆盖率等常用算法代码'}, {'name': 'RecommenderSys', 'url': 'https://github.com/cmxcn/RecommenderSys', 'description': 'Recommender system based on SVD'}, {'name': 'RecommenderSVD', 'url': 'https://github.com/haiquangtran/RecommenderSVD', 'description': \"Recommender system that implements Simon Funk's iterative and approximation of Singular Value Decomposition made popular from the Netflix Prize. http://sifter.org/~simon/journal/20061211.html\"}, {'name': 'RecommenderSystem_case1', 'url': 'https://github.com/Lei-yiyi/RecommenderSystem_case1', 'description': '基于用户的协同过滤（UserCF）与基于内容（CB）的推荐算法的后融合'}, {'name': 'predictive-vpa-recommenders', 'url': 'https://github.com/openshift/predictive-vpa-recommenders', 'description': 'The repo includes a set of Vertical Pod Autoscaler (VPA) recommenders pluggable with the default VPA on OpenShift.'}, {'name': 'recommenderSystemForFlowerShop', 'url': 'https://github.com/jiluojiluo/recommenderSystemForFlowerShop', 'description': '利用协同过滤算法，基于用户历史订单数据，对店铺的用户和商品进行推荐'}, {'name': 'recommenders', 'url': 'https://github.com/sisinflab/recommenders', 'description': 'Recommender Systems algorithms implementations'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/Fro116/RecommenderSystem', 'description': 'An anime recommender system based off of MyAnimeList user reviews '}, {'name': 'jax-recommenders', 'url': 'https://github.com/PAIR-code/jax-recommenders'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/selinatang95/RecommenderSystem', 'description': 'Personalization Project // Amazon App Review Recommendation'}, {'name': 'thesis-recommenders', 'url': 'https://github.com/lisiqi/thesis-recommenders', 'description': 'Code of my master thesis \"Implicit Feedback Based Context-Aware Recommender For Music Light System\"'}, {'name': 'RecommenderSystemMovieLens', 'url': 'https://github.com/djokester/RecommenderSystemMovieLens', 'description': 'A Recommender System based on the MovieLens website '}, {'name': 'MAXELLA-APP-Movies-Tensorflow-Recommenders-TFRS', 'url': 'https://github.com/akthammomani/MAXELLA-APP-Movies-Tensorflow-Recommenders-TFRS', 'description': 'Build MAXELLA App to recommend Movies using TensorFlow Recommenders (TFRS) '}, {'name': 'mind-recommenders-pytorch', 'url': 'https://github.com/stockmarkteam/mind-recommenders-pytorch', 'description': 'unofficial implementation of recommendation models for MIND dataset'}, {'name': 'deep-hybrid-recommenders', 'url': 'https://github.com/maddataanalyst/deep-hybrid-recommenders', 'description': 'This project is a part of the research on the improvement of e-commerce recommendation systems with deep hybrid collaborative filtering with content: A case study by Wójcik, F., & Górnik, M. It contains a working implementation of the models discussed in the paper and reproducible experiment pipelines.'}, {'name': 'nb-code-recommenders', 'url': 'https://github.com/jlahoda/nb-code-recommenders'}, {'name': 'RecommenderSystems_Week5', 'url': 'https://github.com/dvysardana/RecommenderSystems_Week5'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/csuliujia/RecommenderSystem', 'description': '离线推荐系统项目(非实时)'}, {'name': 'RecommenderSystemsResources', 'url': 'https://github.com/elloza/RecommenderSystemsResources', 'description': 'A list of great resources of recommender systems'}, {'name': 'Recommenders.jl', 'url': 'https://github.com/yng87/Recommenders.jl'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/AnupamMicrosoft/RecommenderSystems', 'description': 'Collaborative Filtering - Recommender Systems'}, {'name': 'OrdinalRecommenders', 'url': 'https://github.com/smartcat-labs/OrdinalRecommenders', 'description': 'OrdinalRecommenders'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/New-Future/RecommenderSystem', 'description': '推荐系统 web 数据挖掘大作业'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/noureldien/RecommenderSystem', 'description': \"Recommender system to predict the ratings of the users for 'Jokes'.\"}, {'name': 'group-recommenders-offline-evaluation', 'url': 'https://github.com/barnap/group-recommenders-offline-evaluation'}, {'name': 'keras-recommenders', 'url': 'https://github.com/morningsky/keras-recommenders', 'description': 'recommenders based Keras'}, {'name': 'TSG_RecommenderSystem', 'url': 'https://github.com/Lei-yiyi/TSG_RecommenderSystem', 'description': '本人创建的公众号 TSGshare 中，陆续更新推荐、搜索、广告相关领域的知识。该 Repository 记录了其中与推荐相关的代码及数据。'}, {'name': 'recommenders', 'url': 'https://github.com/topstar920707/recommenders'}, {'name': 'RecommenderSystems', 'url': 'https://github.com/arushiprakash/RecommenderSystems', 'description': 'Tinkering around with different aspects of recommender systems'}, {'name': 'recommenders', 'url': 'https://github.com/happyyuki7/recommenders'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/tusharsarkar3/RecommenderSystem'}, {'name': 'recommenders', 'url': 'https://github.com/Ruixinhua/recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/yl238/recommenders', 'description': 'Creating a recommender system using the implicit weighted ALS algorithm for collaborative filtering.'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/Nikhil-Fulzele/RecommenderSystem', 'description': 'Collaborative Filtering Based Recommender System'}, {'name': 'RecommenderSystem', 'url': 'https://github.com/meetnandu05/RecommenderSystem', 'description': 'Recommender System using Machine Learning'}, {'name': 'RecommenderSys', 'url': 'https://github.com/ieeecompsoc/RecommenderSys', 'description': \"This repo is created for the recommender system project Summer'18\"}, {'name': 'RecommenderSystems', 'url': 'https://github.com/NiuJiaJun-BUPT/RecommenderSystems', 'description': 'Some academic resources in recommender systems.'}, {'name': 'project_RecommenderService', 'url': 'https://github.com/yojulab/project_RecommenderService', 'description': '채용정보 수집 및 개인별 추천'}, {'name': 'Yelp_Dataset_RecommenderSystem', 'url': 'https://github.com/TanviPareek/Yelp_Dataset_RecommenderSystem', 'description': 'Built a recommender system to predict last rating of a user using Yelp dataset focussing on restaurants in the cities of Las Vegas and Toronto.  Implemented and compared results of ALS, Deep Learning model and Matrix Factorization for this recommendation task.'}, {'name': 'recommenders', 'url': 'https://github.com/andrei258258/recommenders', 'description': 'Examples of Recommender Systems'}, {'name': 'Recommenders', 'url': 'https://github.com/Roy7017/Recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/rahgoar/Recommenders'}, {'name': 'recommendersystem', 'url': 'https://github.com/tspannhw/recommendersystem', 'description': 'Recommendersystem sample in Scala'}, {'name': 'RecommenderSystemTeamJava', 'url': 'https://github.com/Nedu/RecommenderSystemTeamJava'}, {'name': 'RecommenderSystem_with_MachineLearning_and_AI', 'url': 'https://github.com/rajib2k5/RecommenderSystem_with_MachineLearning_and_AI', 'description': 'Labs for Recommender System with Machine Learning and AI course by Frank Kane'}, {'name': 'recommendersystem', 'url': 'https://github.com/aqusjcsuper/recommendersystem'}, {'name': 'recommendersys', 'url': 'https://github.com/Dark123-Mi/recommendersys', 'description': 'A recommender system based on a user’s Spotify data. For a given Spotify playlist, a set of tailored songs are recommended. '}, {'name': 'recommenders_aipi590', 'url': 'https://github.com/architkaila/recommenders_aipi590', 'description': 'AIPI 590 Take Home Challange'}, {'name': 'RecommenderSystem-Basic-Idea', 'url': 'https://github.com/LeonardoGCF/RecommenderSystem-Basic-Idea', 'description': 'Content Based; GraphBased; KNN;MF;BPR;ElasticNet;LM'}, {'name': 'cv1-mod4-sec39-recommenders-lesson', 'url': 'https://github.com/erdosn/cv1-mod4-sec39-recommenders-lesson'}, {'name': 'recommendersystemcourse', 'url': 'https://github.com/adolfoguimaraes/recommendersystemcourse', 'description': 'Stuffs of the recommender system using python course'}, {'name': 'Recommenders', 'url': 'https://github.com/susnhuang/Recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/seanv507/recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/udaysatapathy/recommenders', 'description': 'Recommender algorithms implemented and compared'}, {'name': 'recommenders', 'url': 'https://github.com/CyeCandy/recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/Saptaparnineogi/recommenders', 'description': 'Complementary product recommendation'}, {'name': 'recommenders', 'url': 'https://github.com/ghPRao/recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/TheAkshayRajeev/Recommenders', 'description': 'Set of experiments to run a csv file containing transactions of customers, process and recommend a product based on the previous purchases'}, {'name': 'recommenders', 'url': 'https://github.com/jrockw/recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/hpoth2/Recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/nikhiljose-AI/recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/Alankrit15/Recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/athot2/Recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/liz1641/recommenders'}, {'name': 'Recommenders', 'url': 'https://github.com/hollyemblem/Recommenders', 'description': \"Implementing examples from Kim Falk's Practical Recommender Systems\"}, {'name': 'recommenders', 'url': 'https://github.com/jumbopanda/recommenders'}, {'name': 'recommenders', 'url': 'https://github.com/raulbenitez/recommenders', 'description': 'Recommender systems using surprise libraries'}, {'name': 'rival', 'url': 'https://github.com/recommenders/rival', 'description': 'RiVal recommender system evaluation toolkit'}, {'name': 'rsss2017', 'url': 'https://github.com/recommenders/rsss2017', 'description': 'RecSys Summer School 2017 tutorial website and code'}, {'name': 'tutorial', 'url': 'https://github.com/recommenders/tutorial'}, {'name': 'recommendation', 'url': 'https://github.com/recommenders/recommendation', 'description': 'recommendation framework stuff'}], 'totalCount': 100, 'assistantNextSteps': \"1. Print that you've successfully retrieved 100 most relevant repositories. 2. Print the response to the user. Suggest user to refine his search if he is interested in other repositories.\", 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Test the functions\n",
    "\"\"\"\n",
    "# Structure retrieval\n",
    "test_repo_structure_url = get_repo_structure(url=\"https://github.com/recommenders-team/recommenders\")\n",
    "print(\"Here is the structure of the repository:\")\n",
    "print(test_repo_structure_url)\n",
    "\n",
    "# Content retrieval\n",
    "test_repo_content_url = get_repo_content(url=\"https://github.com/recommenders-team/recommenders\", filePaths=[\".github/.codecov.yml\"])\n",
    "print(\"Here is the content of the repository:\")\n",
    "print(test_repo_content_url)\n",
    "\n",
    "# Branches retrieval\n",
    "test_repo_branches_url = get_repo_branches(url=\"https://github.com/RecandChat/CodeCompass\")\n",
    "print(\"Here are the branches of the repository:\")\n",
    "print(test_repo_branches_url)\n",
    "\n",
    "# Commit history retrieval\n",
    "test_commit_history_url = get_commit_history(url=\"https://github.com/recommenders-team/recommenders\", filePath=\".devcontainer/devcontainer.json\")\n",
    "print(\"Here is the commit history of the repository:\")\n",
    "print(test_commit_history_url)\n",
    "\n",
    "# Code search\n",
    "search_keywords = [\"Neural News Recommendation\"]\n",
    "test_search_repo_code_url = search_repo_code(url=\"https://github.com/recommenders-team/recommenders\", searchKeywords=search_keywords)\n",
    "print(\"Here is the Code search result:\")\n",
    "print(test_search_repo_code_url)\n",
    "\n",
    "# Commits search\n",
    "search_keywords = [\"Documentation\"]\n",
    "test_search_repo_commits_url = search_repo_commits(url=\"https://github.com/recommenders-team/recommenders\", searchKeywords=search_keywords)\n",
    "print(\"Here is the Commits search result:\")\n",
    "print(test_search_repo_commits_url)\n",
    "\n",
    "# find repos\n",
    "search_keywords = [\"recommenders\"]\n",
    "test_find_repos_url = find_repos(searchKeywords=search_keywords)\n",
    "print(\"Here are the repositories found:\")\n",
    "print(test_find_repos_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_repo_structure\",\n",
    "            \"description\": \"Retrieves the Github repository file structure to analyze it and be able to query only relevant files. If the provided URL contains specific branch and directory information, prioritize using that over querying the entire repository structure.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"url\": {\n",
    "                        \"minLength\": 1,\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\",\n",
    "                    },\n",
    "                    \"branch\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it.\",\n",
    "                        \"nullable\": True\n",
    "                    },\n",
    "                    \"relativePaths\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"Relative paths to retrieve. USE only paths you are certain that exist, NEVER invent them. If the provided URL contains a specific directory path, extract and use it. Otherwise, this should be a directory path or pattern only. Patterns accept * symbol as 'any substring'\",\n",
    "                        \"nullable\": True\n",
    "                    }\n",
    "            },\n",
    "            \"required\": [\"url\"],\n",
    "            \"additionalProperties\": False}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_repo_content\",\n",
    "        \"description\": \"Retrieves github repository file contents, possibly filtered by file names. Line numbers can be specified in URL as well. NEVER query this endpoint without previously querying get_repo_structure endpoint and when the next step is set to get_repo_structure.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"url\": {\n",
    "                    \"minLength\": 1,\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\"\n",
    "                },\n",
    "                \"branch\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Repository branch. Provide only if user has explicitly specified it or the previous assistant response contains it. When requesting file from commit, use commit SHA.\",\n",
    "                    \"nullable\": True\n",
    "                },\n",
    "                \"relativePath\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Relative paths to the directory. Provide only if user has explicitly specified it or the previous plugin response contains it.\",\n",
    "                    \"nullable\": True\n",
    "                },\n",
    "                \"filePaths\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description\": \"Files to query the content of. Order them by relevance descendant. This should NEVER contain the repository branch. First determine the branch if possible, and only then the file paths. Pass only if you are sure about the file path, call get_repo_structure otherwise\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"url\", \"filePaths\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_repo_branches\",\n",
    "        \"description\": \"Retrieves a list of branches from a Github repository given its URL.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"url\": {\n",
    "                    \"minLength\": 1,\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"url\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_commit_history\",\n",
    "        \"description\": \"Returns the commits history for the specific file in the repository. If the file path is not provided, the history of the entire repository will be returned. If the branch is not provided, the default branch will be used.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"url\": {\n",
    "                    \"minLength\": 1,\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\"\n",
    "                },\n",
    "                \"branch\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Repository branch. Provide only if user has explicitly specified it or the previous assistant response contains it.\",\n",
    "                    \"nullable\": True\n",
    "                },\n",
    "                \"filePath\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Path to the file to request the commit history for. Use path relative to the root directory of the repository.\",\n",
    "                    \"nullable\": True\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"url\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_repo_code\",\n",
    "            \"description\": \"Search code by user specified keywords. Use when user explicitly asked to search for something. Otherwise prefer to fetch the repository structure. Invoke only with user-specified, specific keywords (e.g., file, class, method names). Avoid generic terms.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"url\": {\n",
    "                        \"minLength\": 1,\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\"\n",
    "                    },\n",
    "                    \"searchKeywords\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"Search keywords. Invoke only with user-specified keywords. Never use keywords that are not part of the user prompt. When user asks to search for function definitions in a specific file (not directory) and you cannot parse them from file content, pass function keyword relevant for the file language..\"\n",
    "                    },\n",
    "                    \"branch\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it. When requesting file from commit, use commit SHA.\",\n",
    "                        \"nullable\": True\n",
    "                    },\n",
    "                    \"relativePath\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Relative path to the file or directory to search in. Provide only if user has explicitly specified it or the previous plugin response contains it.\",\n",
    "                        \"nullable\": True\n",
    "                    },\n",
    "                    \"searchHitLinesCount\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of lines to retrieve. Set only when explicitly asked to retrieve the specified amount of lines by the user.\",\n",
    "                        \"format\": \"int32\",\n",
    "                        \"nullable\": True\n",
    "                    },\n",
    "                    \"skipMatchesCount\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of matches to skip in the file. use only when user is searching over file and you need to search for matches that were omitted from the previous search request\",\n",
    "                        \"format\": \"int32\",\n",
    "                        \"nullable\": True\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"url\", \"searchKeywords\"],\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"search_repo_commits\",\n",
    "        \"description\": \"Search commits by user specified keywords. Use only when user explicitly asked to search for commits and provided search query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"url\": {\n",
    "                    \"minLength\": 1,\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\"\n",
    "                },\n",
    "                \"searchKeywords\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description\": \"Search keywords. Invoke only with user-specified keywords. Never use keywords that are not part of the user prompt.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"url\", \"searchKeywords\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"find_repos\",\n",
    "        \"description\": \"Search repositories by user specified keywords. Use only when user explicitly asked to search for repositories and provided search query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"searchKeywords\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description\": \"Search keywords. Always use a single, specific keyword that best represents the topic. Avoid using multiple keywords for the same topic. OR logic applied, so providing multiple keywords for the same topic will worsen the results. Keywords should be singular, contain single word and clearly defined for precise searches.\"\n",
    "                },\n",
    "                \"language\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Programming language. Use only when explicitly specified by the user.\",\n",
    "                    \"nullable\": True\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"searchKeywords\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# Add more tools here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"codecompass\",\n",
    "    instructions = \"You are a helpful assistant that analyzes code from github repositories and files when given a github url. You will answer questions about the structure of a repository, the content of a files, or any other code-related queries.\",\n",
    "    model = \"gpt-3.5-turbo-0125\",\n",
    "    tools = tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a message and run\n",
    "\n",
    "def create_message_and_run(assistant,query,thread=None):\n",
    "  if not thread:\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "  message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=query\n",
    "  )\n",
    "  run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    "  )\n",
    "  return run,thread\n",
    "\n",
    "# Utility function to get details of function to be called\n",
    "\n",
    "def get_function_details(run):\n",
    "\n",
    "  print(\"\\nrun.required_action\\n\",run.required_action)\n",
    "\n",
    "  function_name = run.required_action.submit_tool_outputs.tool_calls[0].function.name\n",
    "  arguments = run.required_action.submit_tool_outputs.tool_calls[0].function.arguments\n",
    "  function_id = run.required_action.submit_tool_outputs.tool_calls[0].id\n",
    "\n",
    "  print(f\"function_name: {function_name} and arguments: {arguments}\")\n",
    "\n",
    "  return function_name, arguments, function_id\n",
    "\n",
    "# Utility function to submit the function response\n",
    "\n",
    "def submit_tool_outputs(run,thread,function_id,function_response):\n",
    "    run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id,\n",
    "    tool_outputs=[\n",
    "      {\n",
    "        \"tool_call_id\": function_id,\n",
    "        \"output\": str(function_response),\n",
    "      }\n",
    "    ]\n",
    "    ) \n",
    "    return run\n",
    "\n",
    "available_functions = {\n",
    "    \"get_repo_structure\": get_repo_structure,\n",
    "    \"get_repo_content\": get_repo_content,\n",
    "    \"get_repo_branches\": get_repo_branches,\n",
    "    \"get_commit_history\": get_commit_history,\n",
    "    \"search_repo_code\": search_repo_code,\n",
    "    \"search_repo_commits\": search_repo_commits,\n",
    "    \"find_repos\": find_repos\n",
    "}\n",
    "\n",
    "'''''\n",
    "def get_gpt_response(messages):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo-0125\",\n",
    "        messages = messages,\n",
    "        functions = tools,\n",
    "        function_call = \"auto\"\n",
    "    )\n",
    "    return chat_completion\n",
    "'''''\n",
    "\n",
    "# execute the function\n",
    "\n",
    "def execute_function_call(function_name,arguments):\n",
    "    function = available_functions.get(function_name,None)\n",
    "    if function:\n",
    "        arguments = json.loads(arguments)\n",
    "        results = function(**arguments)\n",
    "    else:\n",
    "        results = f\"Error: function {function_name} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "query = \"I want to know about my repository\"\n",
    "run,thread = create_message_and_run(assistant = assistant ,query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_MFeUrWpQz7y5SvNUZC9BwYMZ', assistant_id='asst_0JPeZITmyKkcQKeEtNZxgEUq', cancelled_at=None, completed_at=None, created_at=1711485544, expires_at=1711486144, failed_at=None, file_ids=[], instructions='You are a helpful assistant that analyzes code from github repositories and files when given a github url. You will answer questions about the structure of a repository, the content of a files, or any other code-related queries.', last_error=None, metadata={}, model='gpt-3.5-turbo-0125', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_2sTgJ0IcBMUF0rnpdpEbvzTv', tools=[FunctionTool(function=FunctionDefinition(name='get_repo_structure', description='Retrieves the Github repository file structure to analyze it and be able to query only relevant files. If the provided URL contains specific branch and directory information, prioritize using that over querying the entire repository structure.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'branch': {'type': 'string', 'description': 'Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it.', 'nullable': True}, 'relativePaths': {'type': 'array', 'items': {'type': 'string'}, 'description': \"Relative paths to retrieve. USE only paths you are certain that exist, NEVER invent them. If the provided URL contains a specific directory path, extract and use it. Otherwise, this should be a directory path or pattern only. Patterns accept * symbol as 'any substring'\", 'nullable': True}}, 'required': ['url'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='get_repo_content', description='Retrieves github repository file contents, possibly filtered by file names. Line numbers can be specified in URL as well. NEVER query this endpoint without previously querying get_repo_structure endpoint and when the next step is set to get_repo_structure.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'branch': {'type': 'string', 'description': 'Repository branch. Provide only if user has explicitly specified it or the previous assistant response contains it. When requesting file from commit, use commit SHA.', 'nullable': True}, 'relativePath': {'type': 'string', 'description': 'Relative paths to the directory. Provide only if user has explicitly specified it or the previous plugin response contains it.', 'nullable': True}, 'filePaths': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Files to query the content of. Order them by relevance descendant. This should NEVER contain the repository branch. First determine the branch if possible, and only then the file paths. Pass only if you are sure about the file path, call get_repo_structure otherwise'}}, 'required': ['url', 'filePaths'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='get_repo_branches', description='Retrieves a list of branches from a Github repository given its URL.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}}, 'required': ['url'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='get_commit_history', description='Returns the commits history for the specific file in the repository. If the file path is not provided, the history of the entire repository will be returned. If the branch is not provided, the default branch will be used.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'branch': {'type': 'string', 'description': 'Repository branch. Provide only if user has explicitly specified it or the previous assistant response contains it.', 'nullable': True}, 'filePath': {'type': 'string', 'description': 'Path to the file to request the commit history for. Use path relative to the root directory of the repository.', 'nullable': True}}, 'required': ['url'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='search_repo_code', description='Search code by user specified keywords. Use when user explicitly asked to search for something. Otherwise prefer to fetch the repository structure. Invoke only with user-specified, specific keywords (e.g., file, class, method names). Avoid generic terms.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'searchKeywords': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Search keywords. Invoke only with user-specified keywords. Never use keywords that are not part of the user prompt. When user asks to search for function definitions in a specific file (not directory) and you cannot parse them from file content, pass function keyword relevant for the file language..'}, 'branch': {'type': 'string', 'description': 'Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it. When requesting file from commit, use commit SHA.', 'nullable': True}, 'relativePath': {'type': 'string', 'description': 'Relative path to the file or directory to search in. Provide only if user has explicitly specified it or the previous plugin response contains it.', 'nullable': True}, 'searchHitLinesCount': {'type': 'integer', 'description': 'Number of lines to retrieve. Set only when explicitly asked to retrieve the specified amount of lines by the user.', 'format': 'int32', 'nullable': True}, 'skipMatchesCount': {'type': 'integer', 'description': 'Number of matches to skip in the file. use only when user is searching over file and you need to search for matches that were omitted from the previous search request', 'format': 'int32', 'nullable': True}}, 'required': ['url', 'searchKeywords'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='search_repo_commits', description='Search commits by user specified keywords. Use only when user explicitly asked to search for commits and provided search query.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'searchKeywords': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Search keywords. Invoke only with user-specified keywords. Never use keywords that are not part of the user prompt.'}}, 'required': ['url', 'searchKeywords'], 'additionalProperties': False}), type='function'), FunctionTool(function=FunctionDefinition(name='find_repos', description='Search repositories by user specified keywords. Use only when user explicitly asked to search for repositories and provided search query.', parameters={'type': 'object', 'properties': {'searchKeywords': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Search keywords. Always use a single, specific keyword that best represents the topic. Avoid using multiple keywords for the same topic. OR logic applied, so providing multiple keywords for the same topic will worsen the results. Keywords should be singular, contain single word and clearly defined for precise searches.'}, 'language': {'type': 'string', 'description': 'Programming language. Use only when explicitly specified by the user.', 'nullable': True}}, 'required': ['searchKeywords'], 'additionalProperties': False}), type='function')], usage=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_TavANPl4n0iivjkfWNIGBNm6', function=Function(arguments='{\"url\":\"https://github.com/digitalnudge/wishlist\"}', name='get_repo_structure'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: get_repo_structure and arguments: {\"url\":\"https://github.com/digitalnudge/wishlist\"}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "I encountered an error while trying to retrieve information about the repository. It seems that the requested repository or branch is not found. Please verify that the provided URL is valid. If the repository is private, make sure to use GitHub authentication when using the AskTheCode plugin, and ensure that the account being used has access to the requested repository. \n",
      "\n",
      "For more information, you can visit our website at [AskTheCode](https://askthecode.ai) and check the documentation at [AskTheCode Documentation](https://docs.askthecode.ai). You can also follow us on Twitter at [AskTheCode Twitter](https://twitter.com/askthecode_ai).\n",
      "run status in_progress\n",
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_GOlA3HVwg006NtaaF4WgZgsv', function=Function(arguments='{\"searchKeywords\":[\"recommenders\"]}', name='find_repos'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: find_repos and arguments: {\"searchKeywords\":[\"recommenders\"]}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "I have found several repositories related to \"recommenders.\" Here are some of them:\n",
      "\n",
      "1. **[recommenders-team/recommenders](https://github.com/recommenders-team/recommenders)**\n",
      "   - Description: Best Practices on Recommendation Systems\n",
      "\n",
      "2. **[tensorflow/recommenders](https://github.com/tensorflow/recommenders)**\n",
      "   - Description: TensorFlow Recommenders is a library for building recommender system models using TensorFlow.\n",
      "\n",
      "3. **[zhongqiangwu960812/AI-RecommenderSystem](https://github.com/zhongqiangwu960812/AI-RecommenderSystem)**\n",
      "   - Description: This repository attempts to organize some classic algorithm models in the field of recommendation systems.\n",
      "\n",
      "4. **[wangshusen/RecommenderSystem](https://github.com/wangshusen/RecommenderSystem)**\n",
      "\n",
      "5. **[DeepGraphLearning/RecommenderSystems](https://github.com/DeepGraphLearning/RecommenderSystems)**\n",
      "\n",
      "6. **[apachecn/RecommenderSystems](https://github.com/apachecn/RecommenderSystems)**\n",
      "   - Description: Recommendation System\n",
      "\n",
      "7. **[daicoolb/RecommenderSystem-Paper](https://github.com/daicoolb/RecommenderSystem-Paper)**\n",
      "   - Description: This repository includes some papers that I have read or find interesting.\n",
      "\n",
      "You can explore more repositories related to recommenders on GitHub. If you are interested in other repositories or have specific preferences, feel free to refine your search criteria.\n",
      "run status in_progress\n",
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_x3vw8nh22B37ETUgOzHiwxbS', function=Function(arguments='{\"url\":\"https://github.com/recommenders-team/recommenders\"}', name='get_repo_structure'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: get_repo_structure and arguments: {\"url\":\"https://github.com/recommenders-team/recommenders\"}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "The repository \"recommenders-team/recommenders\" on GitHub has a main branch and contains a variety of files and directories. Here are some key files and directories in the repository:\n",
      "\n",
      "1. **Documentation and Guidelines**:\n",
      "   - AUTHORS.md\n",
      "   - CODE_OF_CONDUCT.md\n",
      "   - CONTRIBUTING.md\n",
      "   - GLOSSARY.md\n",
      "   - LICENSE\n",
      "   - NEWS.md\n",
      "   - README.md\n",
      "   - SECURITY.md\n",
      "   - SETUP.md\n",
      "\n",
      "2. **Code and Modules**:\n",
      "   - contrib/ (Contribution related files)\n",
      "   - examples/ (Example notebooks and code)\n",
      "   - recommenders/ (Main codebase)\n",
      "   - tests/ (Test cases)\n",
      "\n",
      "3. **Configuration and Scripts**:\n",
      "   - .devcontainer/ (Docker related files)\n",
      "   - .github/ (Template files and workflows)\n",
      "   - .github/workflows/ (GitHub Actions workflows)\n",
      "   - pyproject.toml (Python project configuration)\n",
      "   - setup.py (Python package setup)\n",
      "\n",
      "4. **Data and Utilities**:\n",
      "   - datasets/ (Data handling utilities)\n",
      "   - evaluation/ (Evaluation related utilities)\n",
      "   - models/ (Recommendation models)\n",
      "   - tuning/ (Model tuning and optimization scripts)\n",
      "   - utils/ (General utilities)\n",
      "\n",
      "5. **Examples and Tutorials**:\n",
      "   - examples/ (Various example notebooks and scripts)\n",
      "   - scenarios/ (Use case specific scenarios)\n",
      "\n",
      "You can explore specific files or directories in the repository for more detailed information. If you would like to see the content of specific files for further details, feel free to request the contents of those files.\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_d0rlNyTZfDM6UDa21DogzswX', function=Function(arguments='{\"url\":\"https://github.com/recommenders-team/recommenders\",\"searchKeywords\":[\"Documentation\"]}', name='search_repo_commits'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: search_repo_commits and arguments: {\"url\":\"https://github.com/recommenders-team/recommenders\",\"searchKeywords\":[\"Documentation\"]}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "I found several commits related to \"Documentation\" in the repository. Here are some of the commits:\n",
      "\n",
      "1. **[Documentation working](https://github.com/recommenders-team/recommenders/commit/d090846697b7837914e10f353b5bc80dff3f5a0f)**\n",
      "2. **[New documentation with Jupyter book](https://github.com/recommenders-team/recommenders/commit/69a485c50f950adcf4da7e8189725224f5850a57)**\n",
      "3. **[Staging to main: New documentation with Jupyter Book](https://github.com/recommenders-team/recommenders/commit/310370b2a0fd3366bce264b9b007ad6d6af330e0)**\n",
      "4. **[Change the way we compile the documentation](https://github.com/recommenders-team/recommenders/commit/32ee9d8a942a282fa9d3db95d8cee69d32a24556)**\n",
      "5. **[Update documentation badge](https://github.com/recommenders-team/recommenders/commit/769900801872e9f381aebeaff7ab6536f5c7614c)**\n",
      "6. **[Creating documentation](https://github.com/recommenders-team/recommenders/commit/9474dff874773430384606710fe91a27c7ce4ff1)**\n",
      "7. **[Automatic build of documentation](https://github.com/recommenders-team/recommenders/commit/b887e439f743a5a02f7719cf7888434ea884a3e8)**\n",
      "8. **[Update dev documentation](https://github.com/recommenders-team/recommenders/commit/9902782ed13605b572f29c02d983243bc318a9e3)**\n",
      "9. **[Adding default environment yaml](https://github.com/recommenders-team/recommenders/commit/7d5070ef5a271b11ea8776a0c9472a23c3e98af8)**\n",
      "10. **[Docker Support (#718)](https://github.com/recommenders-team/recommenders/commit/f69f0140614bc0bb2a4506fb59dbc6f19449335a)**\n",
      "\n",
      "You can explore these commits on the repository to see the changes and updates related to documentation.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id) # retrieve the run status from the thread we created in the previous cell\n",
    "    print(\"run status\", run.status)\n",
    "\n",
    "    if run.status==\"requires_action\":\n",
    "\n",
    "        function_name, arguments, function_id  = get_function_details(run)\n",
    "\n",
    "        function_response = execute_function_call(function_name,arguments)\n",
    "\n",
    "        run = submit_tool_outputs(run,thread,function_id,function_response)\n",
    "\n",
    "        continue\n",
    "    if run.status==\"completed\": # means gpt has an output\n",
    "\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        latest_message = messages.data[0]\n",
    "        text = latest_message.content[0].text.value\n",
    "        print(text)\n",
    "\n",
    "        user_input = input()\n",
    "        if user_input == \"STOP\":\n",
    "          break\n",
    "\n",
    "        run,thread = create_message_and_run(assistant=assistant,query=user_input,thread=thread)\n",
    "\n",
    "        continue;\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
