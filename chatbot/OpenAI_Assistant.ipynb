{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install the latest version of the openai library\n",
    "!pip install openai -q --upgrade\n",
    "\n",
    "# imports\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OpenAI key from a file\n",
    "with open('../secrets/openAI_key', 'r') as file:\n",
    "    openAI_key = file.read().replace('\\n', '')\n",
    "\n",
    "# load the github token\n",
    "with open('../secrets/github_token', 'r') as file:\n",
    "    github_token = file.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the client\n",
    "client = OpenAI(\n",
    "    api_key = openAI_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the structure of the repository:\n",
      "{'branchName': 'main', 'files': ['.devcontainer/Dockerfile', '.devcontainer/devcontainer.json', '.github/.codecov.yml', '.github/CODEOWNERS', '.github/ISSUE_TEMPLATE.md', '.github/ISSUE_TEMPLATE/bug_report.md', '.github/ISSUE_TEMPLATE/feature_request.md', '.github/ISSUE_TEMPLATE/general-ask.md', '.github/PULL_REQUEST_TEMPLATE.md', '.github/actions/azureml-test/action.yml', '.github/actions/get-test-groups/action.yml', '.github/workflows/azureml-cpu-nightly.yml', '.github/workflows/azureml-gpu-nightly.yml', '.github/workflows/azureml-release-pipeline.yml', '.github/workflows/azureml-spark-nightly.yml', '.github/workflows/azureml-unit-tests.yml', '.github/workflows/sarplus.yml', '.github/workflows/update_documentation.yml', 'AUTHORS.md', 'CODE_OF_CONDUCT.md', 'CONTRIBUTING.md', 'GLOSSARY.md', 'LICENSE', 'MANIFEST.in', 'NEWS.md', 'README.md', 'SECURITY.md', 'SETUP.md', 'contrib/README.md', 'contrib/azureml_designer_modules/README.md', 'contrib/azureml_designer_modules/entries/map_entry.py', 'contrib/azureml_designer_modules/entries/ndcg_entry.py', 'contrib/azureml_designer_modules/entries/precision_at_k_entry.py', 'contrib/azureml_designer_modules/entries/recall_at_k_entry.py', 'contrib/azureml_designer_modules/entries/score_sar_entry.py', 'contrib/azureml_designer_modules/entries/stratified_splitter_entry.py', 'contrib/azureml_designer_modules/entries/train_sar_entry.py', 'contrib/azureml_designer_modules/module_specs/map.yaml', 'contrib/azureml_designer_modules/module_specs/ndcg.yaml', 'contrib/azureml_designer_modules/module_specs/precision_at_k.yaml', 'contrib/azureml_designer_modules/module_specs/recall_at_k.yaml', 'contrib/azureml_designer_modules/module_specs/sar_conda.yaml', 'contrib/azureml_designer_modules/module_specs/sar_score.yaml', 'contrib/azureml_designer_modules/module_specs/sar_train.yaml', 'contrib/azureml_designer_modules/module_specs/stratified_splitter.yaml', 'contrib/sarplus/DEVELOPMENT.md', 'contrib/sarplus/README.md', 'contrib/sarplus/VERSION', 'contrib/sarplus/python/.flake8', 'contrib/sarplus/python/README.md', 'contrib/sarplus/python/pyproject.toml', 'contrib/sarplus/python/pysarplus/SARModel.py', 'contrib/sarplus/python/pysarplus/SARPlus.py', 'contrib/sarplus/python/pysarplus/__init__.py', 'contrib/sarplus/python/setup.py', 'contrib/sarplus/python/src/pysarplus.cpp', 'contrib/sarplus/python/tests/conftest.py', 'contrib/sarplus/python/tests/sample-input.txt', 'contrib/sarplus/python/tests/test_pyspark_sar.py', 'contrib/sarplus/scala/build.sbt', 'contrib/sarplus/scala/compat/src/main/scala/com/microsoft/sarplus/compat/spark/since3p2defvisible.scala', 'contrib/sarplus/scala/project/Utils.scala', 'contrib/sarplus/scala/project/build.properties', 'contrib/sarplus/scala/project/plugins.sbt', 'contrib/sarplus/scala/python/pysarplus_dummy/__init__.py', 'contrib/sarplus/scala/python/setup.py', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/DefaultSource.scala', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriter.scala', 'contrib/sarplus/scala/src/main/scala/com/microsoft/sarplus/SARCacheOutputWriterFactory.scala', 'contrib/sarplus/scala/src/test/scala/com/microsoft/sarplus/SARCacheOutputWriterSpec.scala', 'docs/_config.yml', 'docs/_toc.yml', 'docs/datasets.rst', 'docs/evaluation.rst', 'docs/intro.md', 'docs/models.rst', 'docs/requirements-doc.txt', 'docs/tuning.rst', 'docs/utils.rst', 'examples/00_quick_start/README.md', 'examples/00_quick_start/als_movielens.ipynb', 'examples/00_quick_start/dkn_MIND.ipynb', 'examples/00_quick_start/fastai_movielens.ipynb', 'examples/00_quick_start/geoimc_movielens.ipynb', 'examples/00_quick_start/lightgbm_tinycriteo.ipynb', 'examples/00_quick_start/lstur_MIND.ipynb', 'examples/00_quick_start/naml_MIND.ipynb', 'examples/00_quick_start/ncf_movielens.ipynb', 'examples/00_quick_start/npa_MIND.ipynb', 'examples/00_quick_start/nrms_MIND.ipynb', 'examples/00_quick_start/rbm_movielens.ipynb', 'examples/00_quick_start/rlrmc_movielens.ipynb', 'examples/00_quick_start/sar_movielens.ipynb', 'examples/00_quick_start/sar_movielens_with_azureml.ipynb', 'examples/00_quick_start/sar_movieratings_with_azureml_designer.ipynb', 'examples/00_quick_start/sasrec_amazon.ipynb', 'examples/00_quick_start/sequential_recsys_amazondataset.ipynb', 'examples/00_quick_start/tfidf_covid.ipynb', 'examples/00_quick_start/wide_deep_movielens.ipynb', 'examples/00_quick_start/xdeepfm_criteo.ipynb', 'examples/01_prepare_data/README.md', 'examples/01_prepare_data/data_split.ipynb', 'examples/01_prepare_data/data_transform.ipynb', 'examples/01_prepare_data/mind_utils.ipynb', 'examples/01_prepare_data/wikidata_knowledge_graph.ipynb', 'examples/02_model_collaborative_filtering/README.md', 'examples/02_model_collaborative_filtering/als_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/baseline_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/cornac_bivae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/cornac_bpr_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/fm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/lightfm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/lightgcn_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/multi_vae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/ncf_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/rbm_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/sar_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb', 'examples/02_model_collaborative_filtering/surprise_svd_deep_dive.ipynb', 'examples/02_model_content_based_filtering/README.md', 'examples/02_model_content_based_filtering/dkn_deep_dive.ipynb', 'examples/02_model_content_based_filtering/mmlspark_lightgbm_criteo.ipynb', 'examples/02_model_content_based_filtering/vowpal_wabbit_deep_dive.ipynb', 'examples/03_evaluate/README.md', 'examples/03_evaluate/als_movielens_diversity_metrics.ipynb', 'examples/03_evaluate/evaluation.ipynb', 'examples/04_model_select_and_optimize/README.md', 'examples/04_model_select_and_optimize/azureml_hyperdrive_surprise_svd.ipynb', 'examples/04_model_select_and_optimize/azureml_hyperdrive_wide_and_deep.ipynb', 'examples/04_model_select_and_optimize/nni_ncf.ipynb', 'examples/04_model_select_and_optimize/nni_surprise_svd.ipynb', 'examples/04_model_select_and_optimize/train_scripts/svd_training.py', 'examples/04_model_select_and_optimize/train_scripts/wide_deep_training.py', 'examples/04_model_select_and_optimize/tuning_spark_als.ipynb', 'examples/05_operationalize/README.md', 'examples/05_operationalize/aks_locust_load_test.ipynb', 'examples/05_operationalize/als_movie_o16n.ipynb', 'examples/05_operationalize/lightgbm_criteo_o16n.ipynb', 'examples/06_benchmarks/README.md', 'examples/06_benchmarks/benchmark_utils.py', 'examples/06_benchmarks/movielens.ipynb', 'examples/07_tutorials/KDD2020-tutorial/README.md', 'examples/07_tutorials/KDD2020-tutorial/dkn.yaml', 'examples/07_tutorials/KDD2020-tutorial/lightgcn.yaml', 'examples/07_tutorials/KDD2020-tutorial/pandas-subgraph-local-samples.ipynb', 'examples/07_tutorials/KDD2020-tutorial/reco_cpu_kdd.yaml', 'examples/07_tutorials/KDD2020-tutorial/reco_gpu_kdd.yaml', 'examples/07_tutorials/KDD2020-tutorial/run_transE.sh', 'examples/07_tutorials/KDD2020-tutorial/step1_data_preparation.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step2_pretraining-embeddings.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step3_run_dkn.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step4_run_dkn_item2item.ipynb', 'examples/07_tutorials/KDD2020-tutorial/step5_run_lightgcn.ipynb', 'examples/07_tutorials/KDD2020-tutorial/utils/PandasMagClass.py', 'examples/07_tutorials/KDD2020-tutorial/utils/data_helper.py', 'examples/07_tutorials/KDD2020-tutorial/utils/general.py', 'examples/07_tutorials/KDD2020-tutorial/utils/task_helper.py', 'examples/README.md', 'examples/run_notebook_on_azureml.ipynb', 'examples/template.ipynb', 'pyproject.toml', 'recommenders/README.md', 'recommenders/__init__.py', 'recommenders/datasets/__init__.py', 'recommenders/datasets/amazon_reviews.py', 'recommenders/datasets/cosmos_cli.py', 'recommenders/datasets/covid_utils.py', 'recommenders/datasets/criteo.py', 'recommenders/datasets/download_utils.py', 'recommenders/datasets/mind.py', 'recommenders/datasets/movielens.py', 'recommenders/datasets/pandas_df_utils.py', 'recommenders/datasets/python_splitters.py', 'recommenders/datasets/spark_splitters.py', 'recommenders/datasets/sparse.py', 'recommenders/datasets/split_utils.py', 'recommenders/datasets/wikidata.py', 'recommenders/evaluation/__init__.py', 'recommenders/evaluation/python_evaluation.py', 'recommenders/evaluation/spark_evaluation.py', 'recommenders/models/__init__.py', 'recommenders/models/cornac/__init__.py', 'recommenders/models/cornac/cornac_utils.py', 'recommenders/models/deeprec/DataModel/ImplicitCF.py', 'recommenders/models/deeprec/DataModel/__init__.py', 'recommenders/models/deeprec/__init__.py', 'recommenders/models/deeprec/config/asvd.yaml', 'recommenders/models/deeprec/config/caser.yaml', 'recommenders/models/deeprec/config/gru.yaml', 'recommenders/models/deeprec/config/lightgcn.yaml', 'recommenders/models/deeprec/config/nextitnet.yaml', 'recommenders/models/deeprec/config/sli_rec.yaml', 'recommenders/models/deeprec/config/sum.yaml', 'recommenders/models/deeprec/deeprec_utils.py', 'recommenders/models/deeprec/io/__init__.py', 'recommenders/models/deeprec/io/dkn_item2item_iterator.py', 'recommenders/models/deeprec/io/dkn_iterator.py', 'recommenders/models/deeprec/io/iterator.py', 'recommenders/models/deeprec/io/nextitnet_iterator.py', 'recommenders/models/deeprec/io/sequential_iterator.py', 'recommenders/models/deeprec/models/__init__.py', 'recommenders/models/deeprec/models/base_model.py', 'recommenders/models/deeprec/models/dkn.py', 'recommenders/models/deeprec/models/dkn_item2item.py', 'recommenders/models/deeprec/models/graphrec/__init__.py', 'recommenders/models/deeprec/models/graphrec/lightgcn.py', 'recommenders/models/deeprec/models/sequential/__init__.py', 'recommenders/models/deeprec/models/sequential/asvd.py', 'recommenders/models/deeprec/models/sequential/caser.py', 'recommenders/models/deeprec/models/sequential/gru.py', 'recommenders/models/deeprec/models/sequential/nextitnet.py', 'recommenders/models/deeprec/models/sequential/rnn_cell_implement.py', 'recommenders/models/deeprec/models/sequential/sequential_base_model.py', 'recommenders/models/deeprec/models/sequential/sli_rec.py', 'recommenders/models/deeprec/models/sequential/sum.py', 'recommenders/models/deeprec/models/sequential/sum_cells.py', 'recommenders/models/deeprec/models/xDeepFM.py', 'recommenders/models/fastai/__init__.py', 'recommenders/models/fastai/fastai_utils.py', 'recommenders/models/geoimc/__init__.py', 'recommenders/models/geoimc/geoimc_algorithm.py', 'recommenders/models/geoimc/geoimc_data.py', 'recommenders/models/geoimc/geoimc_predict.py', 'recommenders/models/geoimc/geoimc_utils.py', 'recommenders/models/lightfm/__init__.py', 'recommenders/models/lightfm/lightfm_utils.py', 'recommenders/models/lightgbm/__init__.py', 'recommenders/models/lightgbm/lightgbm_utils.py', 'recommenders/models/ncf/__init__.py', 'recommenders/models/ncf/dataset.py', 'recommenders/models/ncf/ncf_singlenode.py', 'recommenders/models/newsrec/__init__.py', 'recommenders/models/newsrec/io/__init__.py', 'recommenders/models/newsrec/io/mind_all_iterator.py', 'recommenders/models/newsrec/io/mind_iterator.py', 'recommenders/models/newsrec/models/__init__.py', 'recommenders/models/newsrec/models/base_model.py', 'recommenders/models/newsrec/models/layers.py', 'recommenders/models/newsrec/models/lstur.py', 'recommenders/models/newsrec/models/naml.py', 'recommenders/models/newsrec/models/npa.py', 'recommenders/models/newsrec/models/nrms.py', 'recommenders/models/newsrec/newsrec_utils.py', 'recommenders/models/rbm/__init__.py', 'recommenders/models/rbm/rbm.py', 'recommenders/models/rlrmc/RLRMCalgorithm.py', 'recommenders/models/rlrmc/RLRMCdataset.py', 'recommenders/models/rlrmc/__init__.py', 'recommenders/models/rlrmc/conjugate_gradient_ms.py', 'recommenders/models/sar/__init__.py', 'recommenders/models/sar/sar_singlenode.py', 'recommenders/models/sasrec/__init__.py', 'recommenders/models/sasrec/model.py', 'recommenders/models/sasrec/sampler.py', 'recommenders/models/sasrec/ssept.py', 'recommenders/models/sasrec/util.py', 'recommenders/models/surprise/__init__.py', 'recommenders/models/surprise/surprise_utils.py', 'recommenders/models/tfidf/__init__.py', 'recommenders/models/tfidf/tfidf_utils.py', 'recommenders/models/vae/__init__.py', 'recommenders/models/vae/multinomial_vae.py', 'recommenders/models/vae/standard_vae.py', 'recommenders/models/vowpal_wabbit/__init__.py', 'recommenders/models/vowpal_wabbit/vw.py', 'recommenders/models/wide_deep/__init__.py', 'recommenders/models/wide_deep/wide_deep_utils.py', 'recommenders/tuning/__init__.py', 'recommenders/tuning/nni/__init__.py', 'recommenders/tuning/nni/ncf_training.py', 'recommenders/tuning/nni/ncf_utils.py', 'recommenders/tuning/nni/nni_utils.py', 'recommenders/tuning/nni/svd_training.py', 'recommenders/tuning/parameter_sweep.py', 'recommenders/utils/__init__.py', 'recommenders/utils/constants.py', 'recommenders/utils/general_utils.py', 'recommenders/utils/gpu_utils.py', 'recommenders/utils/k8s_utils.py', 'recommenders/utils/notebook_memory_management.py', 'recommenders/utils/notebook_utils.py', 'recommenders/utils/plot.py', 'recommenders/utils/python_utils.py', 'recommenders/utils/spark_utils.py', 'recommenders/utils/tf_utils.py', 'recommenders/utils/timer.py', 'scenarios/README.md', 'scenarios/ads/README.md', 'scenarios/food_and_restaurants/README.md', 'scenarios/gaming/README.md', 'scenarios/news/README.md', 'scenarios/retail/README.md', 'scenarios/travel/README.md', 'setup.py', 'tests/README.md', 'tests/__init__.py', 'tests/ci/README.md', 'tests/ci/__init__.py', 'tests/ci/azureml_tests/__init__.py', 'tests/ci/azureml_tests/run_groupwise_pytest.py', 'tests/ci/azureml_tests/submit_groupwise_azureml_pytest.py', 'tests/ci/azureml_tests/test_groups.py', 'tests/conftest.py', 'tests/data_validation/__init__.py', 'tests/data_validation/examples/__init__.py', 'tests/data_validation/examples/test_mind.py', 'tests/data_validation/examples/test_wikidata.py', 'tests/data_validation/recommenders/__init__.py', 'tests/data_validation/recommenders/datasets/__init__.py', 'tests/data_validation/recommenders/datasets/test_covid_utils.py', 'tests/data_validation/recommenders/datasets/test_criteo.py', 'tests/data_validation/recommenders/datasets/test_mind.py', 'tests/data_validation/recommenders/datasets/test_movielens.py', 'tests/data_validation/recommenders/datasets/test_wikidata.py', 'tests/functional/__init__.py', 'tests/functional/examples/__init__.py', 'tests/functional/examples/test_notebooks_gpu.py', 'tests/functional/examples/test_notebooks_pyspark.py', 'tests/functional/examples/test_notebooks_python.py', 'tests/integration/__init__.py', 'tests/integration/recommenders/__init__.py', 'tests/integration/recommenders/utils/__init__.py', 'tests/integration/recommenders/utils/test_k8s_utils.py', 'tests/performance/__init__.py', 'tests/performance/recommenders/__init__.py', 'tests/performance/recommenders/evaluation/__init__.py', 'tests/performance/recommenders/evaluation/test_python_evaluation_time_performance.py', 'tests/regression/__init__.py', 'tests/regression/test_compatibility_tf.py', 'tests/responsible_ai/__init__.py', 'tests/responsible_ai/recommenders/__init__.py', 'tests/responsible_ai/recommenders/datasets/__init__.py', 'tests/responsible_ai/recommenders/datasets/test_criteo_privacy.py', 'tests/responsible_ai/recommenders/datasets/test_movielens_privacy.py', 'tests/security/__init__.py', 'tests/security/test_dependency_security.py', 'tests/smoke/__init__.py', 'tests/smoke/examples/__init__.py', 'tests/smoke/examples/test_notebooks_gpu.py', 'tests/smoke/examples/test_notebooks_pyspark.py', 'tests/smoke/examples/test_notebooks_python.py', 'tests/smoke/recommenders/__init__.py', 'tests/smoke/recommenders/recommender/__init__.py', 'tests/smoke/recommenders/recommender/test_deeprec_model.py', 'tests/smoke/recommenders/recommender/test_deeprec_utils.py', 'tests/smoke/recommenders/recommender/test_newsrec_model.py', 'tests/smoke/recommenders/recommender/test_newsrec_utils.py', 'tests/unit/__init__.py', 'tests/unit/examples/__init__.py', 'tests/unit/examples/test_notebooks_gpu.py', 'tests/unit/examples/test_notebooks_pyspark.py', 'tests/unit/examples/test_notebooks_python.py', 'tests/unit/recommenders/__init__.py', 'tests/unit/recommenders/datasets/__init__.py', 'tests/unit/recommenders/datasets/test_download_utils.py', 'tests/unit/recommenders/datasets/test_pandas_df_utils.py', 'tests/unit/recommenders/datasets/test_python_splitter.py', 'tests/unit/recommenders/datasets/test_spark_splitter.py', 'tests/unit/recommenders/datasets/test_sparse.py', 'tests/unit/recommenders/evaluation/__init__.py', 'tests/unit/recommenders/evaluation/conftest.py', 'tests/unit/recommenders/evaluation/test_python_evaluation.py', 'tests/unit/recommenders/evaluation/test_spark_evaluation.py', 'tests/unit/recommenders/models/__init__.py', 'tests/unit/recommenders/models/test_cornac_utils.py', 'tests/unit/recommenders/models/test_deeprec_model.py', 'tests/unit/recommenders/models/test_deeprec_utils.py', 'tests/unit/recommenders/models/test_geoimc.py', 'tests/unit/recommenders/models/test_lightfm_utils.py', 'tests/unit/recommenders/models/test_ncf_dataset.py', 'tests/unit/recommenders/models/test_ncf_singlenode.py', 'tests/unit/recommenders/models/test_newsrec_model.py', 'tests/unit/recommenders/models/test_newsrec_utils.py', 'tests/unit/recommenders/models/test_rbm.py', 'tests/unit/recommenders/models/test_sar_singlenode.py', 'tests/unit/recommenders/models/test_sasrec_model.py', 'tests/unit/recommenders/models/test_surprise_utils.py', 'tests/unit/recommenders/models/test_tfidf_utils.py', 'tests/unit/recommenders/models/test_vowpal_wabbit.py', 'tests/unit/recommenders/models/test_wide_deep_utils.py', 'tests/unit/recommenders/tuning/__init__.py', 'tests/unit/recommenders/tuning/test_ncf_utils.py', 'tests/unit/recommenders/tuning/test_nni_utils.py', 'tests/unit/recommenders/tuning/test_sweep.py', 'tests/unit/recommenders/utils/__init__.py', 'tests/unit/recommenders/utils/programmatic_notebook_execution.ipynb', 'tests/unit/recommenders/utils/test_general_utils.py', 'tests/unit/recommenders/utils/test_gpu_utils.py', 'tests/unit/recommenders/utils/test_notebook_utils.ipynb', 'tests/unit/recommenders/utils/test_notebook_utils.py', 'tests/unit/recommenders/utils/test_plot.py', 'tests/unit/recommenders/utils/test_python_utils.py', 'tests/unit/recommenders/utils/test_tf_utils.py', 'tests/unit/recommenders/utils/test_timer.py', 'tools/__init__.py', 'tools/databricks_install.py', 'tools/docker/Dockerfile', 'tools/docker/README.md'], 'assistantNextSteps': '1. Thoroughly analyze the repository structure and try to make some assumptions on the content of each file.2. Request contents of no more than 20 files. Order them by relevance descending. ', 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n",
      "Here is the content of the repository:\n",
      "{'branchName': 'main', 'files': [{'path': '.github/.codecov.yml', 'content': '# This file controls how codecov submit comments in the PR about code coverage.\\n# For more details, please see: \\n# https://docs.codecov.com/docs/pull-request-comments#section-behavior\\ncomment:\\n  behavior: default\\n\\nflags:\\n  nightly:\\n    joined: false'}], 'assistantNextSteps': '1. Analyze if the answer to the user question is contained in the returned files. 2. If yes, print the response to the user. If not, try to request the contents of another files.', 'usefulUrls': {'websiteUrl': 'https://askthecode.ai', 'documentationUrl': 'https://docs.askthecode.ai', 'githubUrl': 'https://github.com/askthecode/documentation', 'twitterUrl': 'https://twitter.com/askthecode_ai'}}\n"
     ]
    }
   ],
   "source": [
    "# ASK THE CODE API functions\n",
    "\n",
    "# Get repository structure\n",
    "def get_repo_structure(url, branch=None, relativePaths=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_repo_structure_url = \"https://gabriel.askthecode.ai/api/repository/structure\"\n",
    "\n",
    "    # parameters: url(required), branch(optional), relativePaths(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'branch': branch,\n",
    "        'relativePaths': relativePaths\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_repo_structure_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        structure_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return structure_response\n",
    "    \n",
    "    else:\n",
    "        print(f\"Failed to get the repository structure: {response.status_code}\")\n",
    "\n",
    "\n",
    "# get repo content\n",
    "def get_repo_content(url, filePaths, branch=None, relativePath=None):\n",
    "    # URL of Askthecode API endpoint\n",
    "    get_repo_content_url = \"https://gabriel.askthecode.ai/api/repository/content\"\n",
    "\n",
    "    # parameters: url(required), filePaths(required), branch(optional), relativePath(optional)\n",
    "    params = {\n",
    "        'url': url,\n",
    "        'filePaths': filePaths,\n",
    "        'branch': branch,\n",
    "        'relativePath': relativePath\n",
    "    }\n",
    "\n",
    "    # headers\n",
    "    headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {github_token}\", \n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Make the post request\n",
    "    response = requests.post(get_repo_content_url, json=params, headers=headers)\n",
    "\n",
    "    # check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Parsing the response JSON\n",
    "        content_response = response.json()\n",
    "        # Return the response data instead of printing\n",
    "        return content_response\n",
    "    \n",
    "    else:\n",
    "        print(f\"Failed to get the repository content: {response.status_code}\")\n",
    "\n",
    "\"\"\"\"\n",
    "Test the functions\n",
    "\"\"\"\n",
    "# Structure retrieval\n",
    "test_repo_structure_url = get_repo_structure(url=\"https://github.com/recommenders-team/recommenders\")\n",
    "print(\"Here is the structure of the repository:\")\n",
    "print(test_repo_structure_url)\n",
    "\n",
    "# Content retrieval\n",
    "test_repo_content_url = get_repo_content(url=\"https://github.com/recommenders-team/recommenders\", filePaths=[\".github/.codecov.yml\"])\n",
    "print(\"Here is the content of the repository:\")\n",
    "print(test_repo_content_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistant API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_repo_structure\",\n",
    "            \"description\": \"Retrieves the Github repository file structure to analyze it and be able to query only relevant files. If the provided URL contains specific branch and directory information, prioritize using that over querying the entire repository structure.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"url\": {\n",
    "                        \"minLength\": 1,\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.\",\n",
    "                    },\n",
    "                    \"branch\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it.\",\n",
    "                        \"nullable\": True\n",
    "                    },\n",
    "                    \"relativePaths\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"description\": \"Relative paths to retrieve. USE only paths you are certain that exist, NEVER invent them. If the provided URL contains a specific directory path, extract and use it. Otherwise, this should be a directory path or pattern only. Patterns accept * symbol as 'any substring'\",\n",
    "                        \"nullable\": True\n",
    "                    }\n",
    "            },\n",
    "            \"required\": [\"url\"],\n",
    "            \"additionalProperties\": False}\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Add more tools here\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name = \"codecompass\",\n",
    "    instructions = \"You are a helpful assistant that analyzes code from github repositories and files when given a github url. You will answer questions about the structure of a repository, the content of a files, or any other code-related queries.\",\n",
    "    model = \"gpt-3.5-turbo-0125\",\n",
    "    tools = tools\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a message and run\n",
    "\n",
    "def create_message_and_run(assistant,query,thread=None):\n",
    "  if not thread:\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "  message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=query\n",
    "  )\n",
    "  run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    "  )\n",
    "  return run,thread\n",
    "\n",
    "# Utility function to get details of function to be called\n",
    "\n",
    "def get_function_details(run):\n",
    "\n",
    "  print(\"\\nrun.required_action\\n\",run.required_action)\n",
    "\n",
    "  function_name = run.required_action.submit_tool_outputs.tool_calls[0].function.name\n",
    "  arguments = run.required_action.submit_tool_outputs.tool_calls[0].function.arguments\n",
    "  function_id = run.required_action.submit_tool_outputs.tool_calls[0].id\n",
    "\n",
    "  print(f\"function_name: {function_name} and arguments: {arguments}\")\n",
    "\n",
    "  return function_name, arguments, function_id\n",
    "\n",
    "# Utility function to submit the function response\n",
    "\n",
    "def submit_tool_outputs(run,thread,function_id,function_response):\n",
    "    run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id,\n",
    "    tool_outputs=[\n",
    "      {\n",
    "        \"tool_call_id\": function_id,\n",
    "        \"output\": str(function_response),\n",
    "      }\n",
    "    ]\n",
    "    ) \n",
    "    return run\n",
    "\n",
    "available_functions = {\n",
    "    \"get_repo_structure\": get_repo_structure\n",
    "}\n",
    "\n",
    "def get_gpt_response(messages):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo-0125\",\n",
    "        messages = messages,\n",
    "        functions = functions,\n",
    "        function_call = \"auto\"\n",
    "    )\n",
    "    return chat_completion\n",
    "\n",
    "# execute the function\n",
    "\n",
    "def execute_function_call(function_name,arguments):\n",
    "    function = available_functions.get(function_name,None)\n",
    "    if function:\n",
    "        arguments = json.loads(arguments)\n",
    "        results = function(**arguments)\n",
    "    else:\n",
    "        results = f\"Error: function {function_name} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "query = \"I want to know about my repository\"\n",
    "run,thread = create_message_and_run(assistant = assistant ,query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_GV5GwCtgbmGky0XGlzeT0iht', assistant_id='asst_A2TwKX0j4tonnCBEKQEyxwEW', cancelled_at=None, completed_at=None, created_at=1711472946, expires_at=1711473546, failed_at=None, file_ids=[], instructions='You are a helpful assistant that analyzes code from github repositories and files when given a github url. You will answer questions about the structure of a repository, the content of a files, or any other code-related queries.', last_error=None, metadata={}, model='gpt-3.5-turbo-0125', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_L02tH1oezaPnCkMg4GJDg6mU', tools=[FunctionTool(function=FunctionDefinition(name='get_repo_structure', description='Retrieves the Github repository file structure to analyze it and be able to query only relevant files. If the provided URL contains specific branch and directory information, prioritize using that over querying the entire repository structure.', parameters={'type': 'object', 'properties': {'url': {'minLength': 1, 'type': 'string', 'description': 'Full Github repository URL provided by the user. For example: https://github.com/[owner]/[repo]/blob/[branch]/[file-path]#[additional-parameters]. The URL MUST be identical to the one, that was provided by the user, you MUST NEVER alter or truncate it. This is crucial for valid responses. You should NEVER truncate additional-parameters.'}, 'branch': {'type': 'string', 'description': 'Repository branch. Provide only if user has explicitly specified it or the previous plugin response contains it.', 'nullable': True}, 'relativePaths': {'type': 'array', 'items': {'type': 'string'}, 'description': \"Relative paths to retrieve. USE only paths you are certain that exist, NEVER invent them. If the provided URL contains a specific directory path, extract and use it. Otherwise, this should be a directory path or pattern only. Patterns accept * symbol as 'any substring'\", 'nullable': True}}, 'required': ['url'], 'aditinalProperties': False}), type='function')], usage=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run status in_progress\n",
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_pdGRlZBbCf2rJfmHK9h1c9mV', function=Function(arguments='{\"url\":\"https://github.com/laravel/laravel\"}', name='get_repo_structure'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: get_repo_structure and arguments: {\"url\":\"https://github.com/laravel/laravel\"}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "I have retrieved the structure of the Laravel repository. It is on the branch `11.x` and contains various files and directories, such as `.editorconfig`, `.env.example`, `app/Http/Controllers/Controller.php`, `app/Models/User.php`, `composer.json`, `database/migrations`, `public`, `resources`, `routes`, `tests`, and more.\n",
      "\n",
      "If you have any specific files you would like to see the content of, please let me know.\n",
      "run status in_progress\n",
      "run status requires_action\n",
      "\n",
      "run.required_action\n",
      " RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_qQoUbQg0ANmKFtvF0pQySYs8', function=Function(arguments='{\"url\":\"https://github.com/RecandChat/CodeCompass\"}', name='get_repo_structure'), type='function')]), type='submit_tool_outputs')\n",
      "function_name: get_repo_structure and arguments: {\"url\":\"https://github.com/RecandChat/CodeCompass\"}\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status in_progress\n",
      "run status completed\n",
      "The CodeCompass repository on the `main` branch contains files such as `app.py`, `allReposCleaned.csv`, `backend/__init__.py`, `codecompasslib/models/cosine_modelling_repos.ipynb`, `docs/Project_Proposal.pdf`, `requirements.txt`, `tests/conftest.py`, and more.\n",
      "\n",
      "If you would like to see the content of any specific files, feel free to ask!\n",
      "run status in_progress\n",
      "run status completed\n",
      "I can help you with questions related to code, programming, and GitHub repositories. If you have any other questions or need assistance with code-related queries, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id) # retrieve the run status from the thread we created in the previous cell\n",
    "    print(\"run status\", run.status)\n",
    "\n",
    "    if run.status==\"requires_action\":\n",
    "\n",
    "        function_name, arguments, function_id  = get_function_details(run)\n",
    "\n",
    "        function_response = execute_function_call(function_name,arguments)\n",
    "\n",
    "        run = submit_tool_outputs(run,thread,function_id,function_response)\n",
    "\n",
    "        continue\n",
    "    if run.status==\"completed\": # means gpt has an output\n",
    "\n",
    "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "        latest_message = messages.data[0]\n",
    "        text = latest_message.content[0].text.value\n",
    "        print(text)\n",
    "\n",
    "        user_input = input()\n",
    "        if user_input == \"STOP\":\n",
    "          break\n",
    "\n",
    "        run,thread = create_message_and_run(assistant=assistant,query=user_input,thread=thread)\n",
    "\n",
    "        continue;\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
