{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Cn3Kn4Ti7y"
      },
      "source": [
        "### PyPI `openplugincore`\n",
        "This is the meat of OpenPlugin, it contains all tools you need to interface with ChatGPT plugins as you do on ChatGPT Pro itself.\n",
        "#### Watch out\n",
        "Issues and concerns to look out for\n",
        "- python version : `openplugincore` requires python version >= `3.10`\n",
        "- `You exceeded your current quota` : If your run into an error suggesting `You exceeded your current quota` that could be for several reasons, refer to this [StackOverflow answer](https://stackoverflow.com/a/75898717/9622142) on how to resolve it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOOZLdivTnXR"
      },
      "source": [
        "## Quickstart\n",
        "1. pip install requirements: Versioning is super super important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "from openplugincore import openplugin_completion\n",
        "import json\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the OpenAI key from a file\n",
        "with open('../secrets/openAI_key', 'r') as file:\n",
        "    openAI_key = file.read().replace('\\n', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC1JfG9cTyGV"
      },
      "source": [
        "simplest way to use `openplugincore`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI6mjZ3C0HOq",
        "outputId": "c6078579-c368-463d-a505-24fda0bbeb18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation:  text='' generation_info={'finish_reason': 'function_call'} message=AIMessage(content='', additional_kwargs={'function_call': {'name': 'getRepoReadmeByOwnerAndRepo', 'arguments': '{\\n  \"params\": {\\n    \"owner\": \"recommenders-team\",\\n    \"repo\": \"recommenders\"\\n  }\\n}'}}, example=False)\n",
            "request_chain name: getRepoReadmeByOwnerAndRepo, arguments: {\"params\": {\"owner\": \"recommenders-team\", \"repo\": \"recommenders\"}}\n",
            "{\n",
            "  \"id\": \"chatcmpl-94x1beQCZGkripbFhzLrFIKZOCrRl\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1710967231,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The repository \\\"recommenders\\\" is a project under the Linux Foundation of AI and Data. It aims to assist researchers, developers, and enthusiasts in prototyping, experimenting with, and bringing to production a range of classic and state-of-the-art recommendation systems.\\n\\nThe repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. It covers five key tasks: preparing data, building models using various recommendation algorithms, evaluating algorithms with offline metrics, tuning and optimizing hyperparameters for recommendation models, and operationalizing models in a production environment on Azure.\\n\\nThe repository provides several utilities to support common tasks such as loading datasets, evaluating model outputs, and splitting training/test data. It also includes implementations of several state-of-the-art algorithms for self-study and customization in your own applications.\\n\\nThe repository offers a detailed overview of the available recommendation algorithms, including quick start examples and deep dive explanations of the math and implementation of each algorithm.\\n\\nThe documentation provides instructions for getting started with the repository, including environment management using conda and development using VS Code. It also provides information about setup on different platforms and configurations.\\n\\nIn addition to the core package, the repository provides several extras, including GPU support, Spark support, development tools, and experimental models.\\n\\nOverall, the \\\"recommenders\\\" repository seems to be a comprehensive and well-documented resource for anyone interested in recommendation systems. It offers a wide range of examples, best practices, and algorithms, making it a valuable resource for researchers, developers, and enthusiasts in the field.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1736,\n",
            "    \"completion_tokens\": 305,\n",
            "    \"total_tokens\": 2041\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openplugincore import openplugin_completion\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Review the following repository: https://github.com/recommenders-team/recommenders. \"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "openplugin_completion_generation = openplugin_completion(\n",
        "    openai_api_key = openAI_key,\n",
        "    plugin_name=\"repo_radar\",\n",
        "    truncate = True, # Defaults to True. Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    messages = messages,\n",
        "    model = \"gpt-3.5-turbo-0613\",\n",
        "    temperature = 0,\n",
        ")\n",
        "\n",
        "print(json.dumps(openplugin_completion_generation, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qftm5HWOUGAA"
      },
      "source": [
        "For more nuanced use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzQyF5ecUGcU",
        "outputId": "2abbdabb-8c51-4973-d003-bca2ad14ff61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attempting to load an OpenAPI 3.0.2 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation:  text='' generation_info={'finish_reason': 'function_call'} message=AIMessage(content='', additional_kwargs={'function_call': {'name': 'getSearchResults', 'arguments': '{\\n  \"json\": {\\n    \"query\": \"gangster cat\"\\n  }\\n}'}}, example=False)\n",
            "request_chain name: getSearchResults, arguments: {\"json\": {\"query\": \"gangster cat\"}}\n",
            "function_response {'role': 'function', 'name': 'getSearchResults', 'content': '{\"data\": [{\"url\": \"http://gph.is/1Y74zp8\", \"title\": \"Cat Spin GIF by Keanu Movie\", \"source\": \"\", \"username\": \"keanumovie\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/l2JJvDhbnoSU9e2hW/giphy.gif\"}, {\"url\": \"http://gph.is/1QhK6dO\", \"title\": \"cat kitten GIF by Romy\", \"source\": \"http://www.youtube.com/watch?v=KjEusWO6VPg\", \"username\": \"romy\", \"alt_text\": \"\", \"embed_url\": \"https://media1.giphy.com/media/CUFd8c0eovNio/giphy.gif\"}, {\"url\": \"http://gph.is/1oMzDy3\", \"title\": \"confused cat GIF by Keanu Movie\", \"source\": \"\", \"username\": \"keanumovie\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/xT9DPykKHxZy3hhoLm/giphy.gif\"}, {\"url\": \"http://gph.is/1LOArHG\", \"title\": \"cats gang GIF\", \"source\": \"http://www.reddit.com/r/gifs/comments/3q4mwc/gang_of_cats/\", \"username\": \"\", \"alt_text\": \"\", \"embed_url\": \"https://media4.giphy.com/media/CwWYDU9YQHDnG/giphy.gif\"}, {\"url\": \"https://gph.is/2O6KiQx\", \"title\": \"thug life deal with it GIF by Loly in the sky\", \"source\": \"http://lolyinthesky.com\", \"username\": \"lolyinthesky\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/MT9MUfaFZpWufySsmE/giphy.gif\"}, {\"url\": \"http://gph.is/1U9hLIC\", \"title\": \"cat sparkle GIF by Keanu Movie\", \"source\": \"\", \"username\": \"keanumovie\", \"alt_text\": \"\", \"embed_url\": \"https://media4.giphy.com/media/l41Ye1pJJLVeGnCXS/giphy.gif\"}, {\"url\": \"http://gph.is/2csaS4X\", \"title\": \"hip hop dj cat GIF\", \"source\": \"http://cutecatgifs.com/tag/dj\", \"username\": \"\", \"alt_text\": \"\", \"embed_url\": \"https://media1.giphy.com/media/T7ukTzXQVmWqI/giphy.gif\"}, {\"url\": \"https://gph.is/g/Zkbybvm\", \"title\": \"Bad Boy Deal With It GIF by TikTok\", \"source\": \"\", \"username\": \"tiktok\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/WoRz0xf3fUBWTWXUJ0/giphy.gif\"}, {\"url\": \"http://gph.is/KpX7EM\", \"title\": \"space cat GIF\", \"source\": \"http://caravangogh.tumblr.com/post/72193183515\", \"username\": \"\", \"alt_text\": \"\", \"embed_url\": \"https://media4.giphy.com/media/w2JmkbOHFoq8U/giphy.gif\"}, {\"url\": \"https://gph.is/g/E0020Mp\", \"title\": \"Bad Boy Deal With It GIF by TikTok\", \"source\": \"\", \"username\": \"tiktok\", \"alt_text\": \"\", \"embed_url\": \"https://media2.giphy.com/media/Ynx9CV7G7uYWpEZU2s/giphy.gif\"}, {\"url\": \"https://gph.is/g/E1PLA5w\", \"title\": \"Cats Nft GIF by SuperVictor\", \"source\": \"\", \"username\": \"SuperVictorUniverse\", \"alt_text\": \"\", \"embed_url\": \"https://media0.giphy.com/media/902zvoIGwxpyrlWPZ1/giphy.gif\"}, {\"url\": \"https://gph.is/g/EqweQBp\", \"title\": \"Gang You Want To Fight GIF by Riot Society\", \"source\": \"https://riotsociety.com/\", \"username\": \"riotsociety\", \"alt_text\": \"\", \"embed_url\": \"https://media4.giphy.com/media/JYdXaGS9iqt9ErMbgv/giphy.gif\"}, {\"url\": \"https://gph.is/g/ZOon86P\", \"title\": \"Hungry Cat GIF by LorenzoTheGawd\", \"source\": \"http://lorenzothegawd.com\", \"username\": \"LorenzoTheGawd\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/wT5DljWazWryfih0GI/giphy.gif\"}, {\"url\": \"http://gph.is/1HPlmJd\", \"title\": \"Hustling Sabrina The Teenage Witch GIF\", \"source\": \"http://jhonpierce.tumblr.com/post/49234141185\", \"username\": \"\", \"alt_text\": \"\", \"embed_url\": \"https://media3.giphy.com/media/itlZYnhGQUHdK/giphy.gif\"}, {\"url\": \"https://gph.is/g/4bAMPxG\", \"title\": \"Cat Hiphop GIF\", \"source\": \"\", \"username\": \"hoodycats\", \"alt_text\": \"\", \"embed_url\": \"https://media1.giphy.com/media/27x2UXmebfgpDbXsIQ/giphy.gif\"}]}'}\n",
            "{\n",
            "  \"id\": \"chatcmpl-94x1q4YXRNwdqZvX0YkOvJ0e0ARuA\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1710967246,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"Here are some GIFs of gangster cats:\\n\\n1. ![Cat Spin GIF by Keanu Movie](https://media3.giphy.com/media/l2JJvDhbnoSU9e2hW/giphy.gif)\\n2. ![cat kitten GIF by Romy](https://media1.giphy.com/media/CUFd8c0eovNio/giphy.gif)\\n3. ![confused cat GIF by Keanu Movie](https://media3.giphy.com/media/xT9DPykKHxZy3hhoLm/giphy.gif)\\n4. ![cats gang GIF](https://media4.giphy.com/media/CwWYDU9YQHDnG/giphy.gif)\\n5. ![thug life deal with it GIF by Loly in the sky](https://media3.giphy.com/media/MT9MUfaFZpWufySsmE/giphy.gif)\\n6. ![cat sparkle GIF by Keanu Movie](https://media4.giphy.com/media/l41Ye1pJJLVeGnCXS/giphy.gif)\\n7. ![hip hop dj cat GIF](https://media1.giphy.com/media/T7ukTzXQVmWqI/giphy.gif)\\n8. ![Bad Boy Deal With It GIF by TikTok](https://media3.giphy.com/media/WoRz0xf3fUBWTWXUJ0/giphy.gif)\\n9. ![space cat GIF](https://media4.giphy.com/media/w2JmkbOHFoq8U/giphy.gif)\\n10. ![Bad Boy Deal With It GIF by TikTok](https://media2.giphy.com/media/Ynx9CV7G7uYWpEZU2s/giphy.gif)\\n\\nPlease note that the content of these GIFs may vary, and some may not exactly depict a gangster cat.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1261,\n",
            "    \"completion_tokens\": 389,\n",
            "    \"total_tokens\": 1650\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openplugincore import OpenPlugin\n",
        "\n",
        "plugin = OpenPlugin(\"GifApi\", openAI_key)\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"show me a gif of a gangster cat\"\n",
        "    }\n",
        "]\n",
        "\n",
        "function_response = plugin.fetch_plugin(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages = messages,\n",
        "    truncate = True, # Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    temperature=0,\n",
        ")\n",
        "print(\"function_response\", function_response)\n",
        "\n",
        "OpenPlugin_generation = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages= messages + [function_response],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(json.dumps(OpenPlugin_generation, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvnQW5NKUNGU"
      },
      "source": [
        "and to be respectful to plugin APIs you can use `OpenPluginMemo`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AMkIRaaUKMl",
        "outputId": "51095142-4e82-4086-f3da-0d5ac92027c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MEMO READY\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n",
            "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generation:  text='' generation_info={'finish_reason': 'function_call'} message=AIMessage(content='', additional_kwargs={'function_call': {'name': 'getRepoReadmeByOwnerAndRepo', 'arguments': '{\\n  \"params\": {\\n    \"owner\": \"recommenders-team\",\\n    \"repo\": \"recommenders\"\\n  }\\n}'}}, example=False)\n",
            "request_chain name: getRepoReadmeByOwnerAndRepo, arguments: {\"params\": {\"owner\": \"recommenders-team\", \"repo\": \"recommenders\"}}\n",
            "{\n",
            "  \"id\": \"chatcmpl-94x2BxVZK9dUrS8GYzRkpp6Akl2MG\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1710967267,\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"The examples directory in the repository contains Jupyter notebooks that demonstrate how to build recommendation systems using various algorithms. Some of the code examples in the examples directory include:\\n\\n1. [Prepare Data](examples/01_prepare_data): This directory contains notebooks that demonstrate how to prepare and load data for each recommendation algorithm.\\n\\n2. [Model](examples/00_quick_start): This directory contains notebooks that show how to build recommendation models using classical and deep learning algorithms such as Alternating Least Squares (ALS) and eXtreme Deep Factorization Machines (xDeepFM).\\n\\n3. [Evaluate](examples/03_evaluate): This directory contains notebooks that demonstrate how to evaluate recommendation algorithms using offline metrics.\\n\\n4. [Model Select and Optimize](examples/04_model_select_and_optimize): This directory contains notebooks that explain how to tune and optimize hyperparameters for recommendation models.\\n\\n5. [Operationalize](examples/05_operationalize): This directory contains notebooks that show how to operationalize recommendation models in a production environment on Azure.\\n\\nThese examples provide a comprehensive guide for researchers, developers, and enthusiasts to prototype, experiment with, and deploy recommendation systems using the Recommenders library.\"\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1730,\n",
            "    \"completion_tokens\": 236,\n",
            "    \"total_tokens\": 1966\n",
            "  },\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from openplugincore import OpenPluginMemo\n",
        "\n",
        "open_plugin_memo = OpenPluginMemo() # Stores the plugin's config in memory so that it does not need to call the API to fetch the config every time the plugin is initialize.\n",
        "open_plugin_memo.init()\n",
        "\n",
        "plugin = open_plugin_memo.get_plugin('repo_radar') # returns the plugin if it is already initialized, otherwise returns None\n",
        "if plugin is None: # in this demo it returns None\n",
        "    plugin = open_plugin_memo.init_plugin('repo_radar') # initializes the plugin\n",
        "\n",
        "# the rest is the same as using the OpenPlugin class\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Review the following repository: https://github.com/recommenders-team/recommenders. What is some of the code in the examples directory?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "function_response = plugin.fetch_plugin(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages = messages,\n",
        "    truncate = True, # Truncates the plugin API response to ensure the LLM's token limit is not exceeded\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "OpenPlugin_generation = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo-0613\",\n",
        "    messages= messages + [function_response],\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "print(json.dumps(OpenPlugin_generation, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
